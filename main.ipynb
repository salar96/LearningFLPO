{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning FLPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we will implement the hierarchical ML architecture to predict the parameters in the FLPO setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from VRP_Net_L import VRPNet_L\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import LSE_net\n",
    "from torch import optim\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5348, 0.3069])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.tensor([0.3,0.3]), std=torch.tensor([0.1,0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n",
      "Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed=42;\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Running on: \" , device)\n",
    "num_drones = 100 # number of FLPO instances\n",
    "num_facilities = 4\n",
    "dim_ = 2\n",
    "# START and END locations: no grads needed\n",
    "nd_per_cluster = int(num_drones/2)\n",
    "means1 = torch.tensor([[0.4,0.7]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "means2 = torch.tensor([[0.7,0.3]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std2 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "START_locs1 = torch.normal(mean=means1, std=std1)\n",
    "START_locs2 = torch.normal(mean=means2, std=std2)\n",
    "START_locs = torch.cat((START_locs1, START_locs2), axis=0)\n",
    "END_locs   = torch.ones((num_drones, 1, dim_), requires_grad=False, device=device)#torch.rand(num_drones, 1, dim_, requires_grad=False, device=device)\n",
    "\n",
    "# Facility locations: we want grads here\n",
    "# We create a base tensor with requires_grad=True, then expand it\n",
    "# F_base = torch.rand(1, num_facilities, dim_, requires_grad=True, device=device)\n",
    "F_base = torch.mean(START_locs, dim=0).repeat(num_facilities, 1).unsqueeze(0).requires_grad_().to(device)\n",
    "F_locs = F_base.expand(num_drones, -1, -1)  # view, shares grad with F_base\n",
    "data = torch.cat((START_locs, F_locs, END_locs), dim=1)  # shape: (Nd, Nf+2, D)\n",
    "print(\"Data Loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute n_routes from each drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.]])\n",
      "log_n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319]])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "n_drone_routes = torch.tensor(utils.num_flpo_routes(num_facilities, num_drones)[0], dtype=torch.float32).view(-1,1).to(device)\n",
    "print(f\"n_routes:\\t{n_drone_routes.shape}\\n{n_drone_routes}\\nlog_n_routes:\\t{n_drone_routes.shape}\\n{torch.log(n_drone_routes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the VRP NET Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRP NET loaded on:  cpu\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "VRPNet_L                                                               --\n",
      "├─LinearAttnEncoder: 1-1                                               2,560\n",
      "│    └─MultiheadAttention: 2-1                                         197,376\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-1                       65,792\n",
      "│    └─Linear: 2-2                                                     768\n",
      "│    └─Linear: 2-3                                                     8,224\n",
      "│    └─LayerNorm: 2-4                                                  512\n",
      "│    └─Dropout: 2-5                                                    --\n",
      "│    └─ReLU: 2-6                                                       --\n",
      "├─Decoder: 1-2                                                         --\n",
      "│    └─TransformerDecoder: 2-7                                         --\n",
      "│    │    └─ModuleList: 3-2                                            16,992\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "===============================================================================================\n",
      "Total params: 292,224\n",
      "Trainable params: 292,224\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "num_layers_enc = 1\n",
    "num_layers_dec = 1\n",
    "num_heads = 8\n",
    "torch.cuda.empty_cache()\n",
    "vrp_net = VRPNet_L(dim_, hidden_dim, device, num_layers_enc, num_layers_dec, num_heads)\n",
    "if torch.cuda.is_available():\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=True))\n",
    "else:\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=False, map_location=torch.device('cpu')))\n",
    "vrp_net.eval()\n",
    "\n",
    "# for param in vrp_net.parameters():\n",
    "#     param.requires_grad = False\n",
    "print('VRP NET loaded on: ',vrp_net.device)\n",
    "print(summary(vrp_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading lseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs: 3\n",
      "n_outputs: 1\n",
      "layers: [20, 20, 10]\n",
      "io_scale: 1\n",
      "LSE_net:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "dnn                                      --\n",
      "├─ModuleList: 1-1                        --\n",
      "│    └─Linear: 2-1                       (80)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Linear: 2-3                       (420)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       (210)\n",
      "│    └─ReLU: 2-6                         --\n",
      "│    └─Linear: 2-7                       (11)\n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 0\n",
      "Non-trainable params: 721\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(LSE_net)\n",
    "lse_data = torch.load('logSumExp_models/lse_2025_4_29__17_9_17.pth', weights_only=False)\n",
    "n_inputs = lse_data['n_inputs']\n",
    "n_outputs = lse_data['n_outputs']\n",
    "layers = lse_data['layers']\n",
    "weights = lse_data['model_state_dict']\n",
    "io_scale = lse_data['io_scale']\n",
    "lse_net = LSE_net.dnn(n_inputs, n_outputs, layers)\n",
    "lse_net.to(device)\n",
    "lse_net.load_state_dict(weights)\n",
    "lse_net.eval()\n",
    "for p in lse_net.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f'n_inputs: {n_inputs}\\nn_outputs: {n_outputs}\\nlayers: {layers}\\nio_scale: {io_scale}\\nLSE_net:\\n{summary(lse_net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([10,10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSumExp(D_tensor, beta):\n",
    "    # with torch.no_grad():\n",
    "    # print(D_tensor)\n",
    "    D_min = torch.min(D_tensor, axis=1, keepdims=True)\n",
    "    F = -1/beta * torch.log(torch.sum(torch.exp(-beta*(D_tensor - D_min.values)), axis=1, keepdims=True)) + 1/beta * torch.log(torch.tensor([D_tensor.shape[1]])) + D_min.values\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a random variable matrix with iid entries of shape shape (a,b) between [r1, r2] at uniform using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 3\n",
    "# b = 2\n",
    "# r1 = 0.5\n",
    "# r2 = 10.0\n",
    "# (r1 - r2) * torch.rand(a,b) + r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "with torch.no_grad():\n",
    "    # forward pass: no activations are saved for grad\n",
    "    _, actions = vrp_net(data, mod='eval_greedy')\n",
    "e = time.time()\n",
    "actions.detach()\n",
    "d_mins = utils.route_cost(data, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5197],\n",
       "        [0.4645],\n",
       "        [0.4761],\n",
       "        [0.4811],\n",
       "        [0.5550],\n",
       "        [0.4888],\n",
       "        [0.5065],\n",
       "        [0.5331],\n",
       "        [0.4845],\n",
       "        [0.5212],\n",
       "        [0.5403],\n",
       "        [0.5335],\n",
       "        [0.5189],\n",
       "        [0.5264],\n",
       "        [0.5088],\n",
       "        [0.5265],\n",
       "        [0.5147],\n",
       "        [0.5479],\n",
       "        [0.4925],\n",
       "        [0.4871],\n",
       "        [0.5546],\n",
       "        [0.5087],\n",
       "        [0.5787],\n",
       "        [0.5175],\n",
       "        [0.5084],\n",
       "        [0.5141],\n",
       "        [0.5384],\n",
       "        [0.5053],\n",
       "        [0.5305],\n",
       "        [0.5194],\n",
       "        [0.5495],\n",
       "        [0.5563],\n",
       "        [0.5069],\n",
       "        [0.4953],\n",
       "        [0.4961],\n",
       "        [0.5510],\n",
       "        [0.5177],\n",
       "        [0.5123],\n",
       "        [0.4858],\n",
       "        [0.5358],\n",
       "        [0.4982],\n",
       "        [0.5182],\n",
       "        [0.5082],\n",
       "        [0.4838],\n",
       "        [0.5272],\n",
       "        [0.4954],\n",
       "        [0.5291],\n",
       "        [0.4990],\n",
       "        [0.5236],\n",
       "        [0.5124],\n",
       "        [0.5260],\n",
       "        [0.4993],\n",
       "        [0.6023],\n",
       "        [0.5409],\n",
       "        [0.5285],\n",
       "        [0.5196],\n",
       "        [0.4973],\n",
       "        [0.5195],\n",
       "        [0.4857],\n",
       "        [0.5153],\n",
       "        [0.5114],\n",
       "        [0.5010],\n",
       "        [0.4909],\n",
       "        [0.4936],\n",
       "        [0.5198],\n",
       "        [0.5110],\n",
       "        [0.5242],\n",
       "        [0.5032],\n",
       "        [0.5798],\n",
       "        [0.4831],\n",
       "        [0.5015],\n",
       "        [0.4850],\n",
       "        [0.5181],\n",
       "        [0.4986],\n",
       "        [0.5367],\n",
       "        [0.5441],\n",
       "        [0.5394],\n",
       "        [0.5047],\n",
       "        [0.4829],\n",
       "        [0.4966],\n",
       "        [0.5988],\n",
       "        [0.5041],\n",
       "        [0.5428],\n",
       "        [0.5126],\n",
       "        [0.5015],\n",
       "        [0.5162],\n",
       "        [0.5916],\n",
       "        [0.5139],\n",
       "        [0.5140],\n",
       "        [0.5103],\n",
       "        [0.4934],\n",
       "        [0.4995],\n",
       "        [0.5116],\n",
       "        [0.5744],\n",
       "        [0.4893],\n",
       "        [0.5132],\n",
       "        [0.5348],\n",
       "        [0.5195],\n",
       "        [0.5222],\n",
       "        [0.5392]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mins.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7677],\n",
       "        [0.7311],\n",
       "        [0.7429],\n",
       "        [0.7362],\n",
       "        [0.7811],\n",
       "        [0.7370],\n",
       "        [0.7528],\n",
       "        [0.7598],\n",
       "        [0.7268],\n",
       "        [0.7637],\n",
       "        [0.7753],\n",
       "        [0.7720],\n",
       "        [0.7421],\n",
       "        [0.7562],\n",
       "        [0.7546],\n",
       "        [0.7651],\n",
       "        [0.7506],\n",
       "        [0.7912],\n",
       "        [0.7503],\n",
       "        [0.7412],\n",
       "        [0.7703],\n",
       "        [0.7519],\n",
       "        [0.7924],\n",
       "        [0.7640],\n",
       "        [0.7670],\n",
       "        [0.7620],\n",
       "        [0.7836],\n",
       "        [0.7446],\n",
       "        [0.7592],\n",
       "        [0.7684],\n",
       "        [0.7684],\n",
       "        [0.7789],\n",
       "        [0.7503],\n",
       "        [0.7495],\n",
       "        [0.7580],\n",
       "        [0.7746],\n",
       "        [0.7535],\n",
       "        [0.7667],\n",
       "        [0.7448],\n",
       "        [0.7630],\n",
       "        [0.7456],\n",
       "        [0.7657],\n",
       "        [0.7638],\n",
       "        [0.7454],\n",
       "        [0.7619],\n",
       "        [0.7518],\n",
       "        [0.7696],\n",
       "        [0.7615],\n",
       "        [0.7580],\n",
       "        [0.7556],\n",
       "        [0.7644],\n",
       "        [0.7427],\n",
       "        [0.7986],\n",
       "        [0.7803],\n",
       "        [0.7564],\n",
       "        [0.7581],\n",
       "        [0.7369],\n",
       "        [0.7610],\n",
       "        [0.7400],\n",
       "        [0.7703],\n",
       "        [0.7555],\n",
       "        [0.7529],\n",
       "        [0.7449],\n",
       "        [0.7515],\n",
       "        [0.7668],\n",
       "        [0.7464],\n",
       "        [0.7660],\n",
       "        [0.7458],\n",
       "        [0.7826],\n",
       "        [0.7534],\n",
       "        [0.7439],\n",
       "        [0.7327],\n",
       "        [0.7725],\n",
       "        [0.7370],\n",
       "        [0.7597],\n",
       "        [0.7789],\n",
       "        [0.7664],\n",
       "        [0.7596],\n",
       "        [0.7489],\n",
       "        [0.7391],\n",
       "        [0.7982],\n",
       "        [0.7466],\n",
       "        [0.7637],\n",
       "        [0.7474],\n",
       "        [0.7561],\n",
       "        [0.7588],\n",
       "        [0.8066],\n",
       "        [0.7565],\n",
       "        [0.7604],\n",
       "        [0.7491],\n",
       "        [0.7367],\n",
       "        [0.7435],\n",
       "        [0.7473],\n",
       "        [0.7898],\n",
       "        [0.7472],\n",
       "        [0.7489],\n",
       "        [0.7697],\n",
       "        [0.7666],\n",
       "        [0.7452],\n",
       "        [0.7739]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    D_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "    F_tensor = logSumExp(D_tensor, beta=1e-4)\n",
    "F_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7264]], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7264,  0.4645, -2.0000])\n",
      "tensor([ 0.7264,  0.4645, -1.9957])\n",
      "tensor([ 0.7264,  0.4645, -1.9914])\n",
      "tensor([ 0.7264,  0.4645, -1.9870])\n",
      "tensor([ 0.7264,  0.4645, -1.9827])\n",
      "tensor([ 0.7264,  0.4645, -1.9784])\n",
      "tensor([ 0.7264,  0.4645, -1.9741])\n",
      "tensor([ 0.7264,  0.4645, -1.9698])\n",
      "tensor([ 0.7264,  0.4645, -1.9654])\n",
      "tensor([ 0.7264,  0.4645, -1.9611])\n",
      "tensor([ 0.7264,  0.4645, -1.9568])\n",
      "tensor([ 0.7264,  0.4645, -1.9525])\n",
      "tensor([ 0.7264,  0.4645, -1.9481])\n",
      "tensor([ 0.7264,  0.4645, -1.9438])\n",
      "tensor([ 0.7264,  0.4645, -1.9395])\n",
      "tensor([ 0.7264,  0.4645, -1.9352])\n",
      "tensor([ 0.7264,  0.4645, -1.9309])\n",
      "tensor([ 0.7264,  0.4645, -1.9265])\n",
      "tensor([ 0.7264,  0.4645, -1.9222])\n",
      "tensor([ 0.7264,  0.4645, -1.9179])\n",
      "tensor([ 0.7264,  0.4645, -1.9136])\n",
      "tensor([ 0.7264,  0.4645, -1.9093])\n",
      "tensor([ 0.7264,  0.4645, -1.9049])\n",
      "tensor([ 0.7264,  0.4645, -1.9006])\n",
      "tensor([ 0.7264,  0.4645, -1.8963])\n",
      "tensor([ 0.7264,  0.4645, -1.8920])\n",
      "tensor([ 0.7264,  0.4645, -1.8876])\n",
      "tensor([ 0.7264,  0.4645, -1.8833])\n",
      "tensor([ 0.7264,  0.4645, -1.8790])\n",
      "tensor([ 0.7264,  0.4645, -1.8747])\n",
      "tensor([ 0.7264,  0.4645, -1.8704])\n",
      "tensor([ 0.7264,  0.4645, -1.8660])\n",
      "tensor([ 0.7264,  0.4645, -1.8617])\n",
      "tensor([ 0.7264,  0.4645, -1.8574])\n",
      "tensor([ 0.7264,  0.4645, -1.8531])\n",
      "tensor([ 0.7264,  0.4645, -1.8488])\n",
      "tensor([ 0.7264,  0.4645, -1.8444])\n",
      "tensor([ 0.7264,  0.4645, -1.8401])\n",
      "tensor([ 0.7264,  0.4645, -1.8358])\n",
      "tensor([ 0.7264,  0.4645, -1.8315])\n",
      "tensor([ 0.7264,  0.4645, -1.8271])\n",
      "tensor([ 0.7264,  0.4645, -1.8228])\n",
      "tensor([ 0.7264,  0.4645, -1.8185])\n",
      "tensor([ 0.7264,  0.4645, -1.8142])\n",
      "tensor([ 0.7264,  0.4645, -1.8099])\n",
      "tensor([ 0.7264,  0.4645, -1.8055])\n",
      "tensor([ 0.7264,  0.4645, -1.8012])\n",
      "tensor([ 0.7264,  0.4645, -1.7969])\n",
      "tensor([ 0.7264,  0.4645, -1.7926])\n",
      "tensor([ 0.7264,  0.4645, -1.7883])\n",
      "tensor([ 0.7264,  0.4645, -1.7839])\n",
      "tensor([ 0.7264,  0.4645, -1.7796])\n",
      "tensor([ 0.7264,  0.4645, -1.7753])\n",
      "tensor([ 0.7264,  0.4645, -1.7710])\n",
      "tensor([ 0.7264,  0.4645, -1.7666])\n",
      "tensor([ 0.7264,  0.4645, -1.7623])\n",
      "tensor([ 0.7264,  0.4645, -1.7580])\n",
      "tensor([ 0.7264,  0.4645, -1.7537])\n",
      "tensor([ 0.7264,  0.4645, -1.7494])\n",
      "tensor([ 0.7264,  0.4645, -1.7450])\n",
      "tensor([ 0.7264,  0.4645, -1.7407])\n",
      "tensor([ 0.7264,  0.4645, -1.7364])\n",
      "tensor([ 0.7264,  0.4645, -1.7321])\n",
      "tensor([ 0.7264,  0.4645, -1.7278])\n",
      "tensor([ 0.7264,  0.4645, -1.7234])\n",
      "tensor([ 0.7264,  0.4645, -1.7191])\n",
      "tensor([ 0.7264,  0.4645, -1.7148])\n",
      "tensor([ 0.7264,  0.4645, -1.7105])\n",
      "tensor([ 0.7264,  0.4645, -1.7061])\n",
      "tensor([ 0.7264,  0.4645, -1.7018])\n",
      "tensor([ 0.7264,  0.4645, -1.6975])\n",
      "tensor([ 0.7264,  0.4645, -1.6932])\n",
      "tensor([ 0.7264,  0.4645, -1.6889])\n",
      "tensor([ 0.7264,  0.4645, -1.6845])\n",
      "tensor([ 0.7264,  0.4645, -1.6802])\n",
      "tensor([ 0.7264,  0.4645, -1.6759])\n",
      "tensor([ 0.7264,  0.4645, -1.6716])\n",
      "tensor([ 0.7264,  0.4645, -1.6673])\n",
      "tensor([ 0.7264,  0.4645, -1.6629])\n",
      "tensor([ 0.7264,  0.4645, -1.6586])\n",
      "tensor([ 0.7264,  0.4645, -1.6543])\n",
      "tensor([ 0.7264,  0.4645, -1.6500])\n",
      "tensor([ 0.7264,  0.4645, -1.6456])\n",
      "tensor([ 0.7264,  0.4645, -1.6413])\n",
      "tensor([ 0.7264,  0.4645, -1.6370])\n",
      "tensor([ 0.7264,  0.4645, -1.6327])\n",
      "tensor([ 0.7264,  0.4645, -1.6284])\n",
      "tensor([ 0.7264,  0.4645, -1.6240])\n",
      "tensor([ 0.7264,  0.4645, -1.6197])\n",
      "tensor([ 0.7264,  0.4645, -1.6154])\n",
      "tensor([ 0.7264,  0.4645, -1.6111])\n",
      "tensor([ 0.7264,  0.4645, -1.6068])\n",
      "tensor([ 0.7264,  0.4645, -1.6024])\n",
      "tensor([ 0.7264,  0.4645, -1.5981])\n",
      "tensor([ 0.7264,  0.4645, -1.5938])\n",
      "tensor([ 0.7264,  0.4645, -1.5895])\n",
      "tensor([ 0.7264,  0.4645, -1.5851])\n",
      "tensor([ 0.7264,  0.4645, -1.5808])\n",
      "tensor([ 0.7264,  0.4645, -1.5765])\n",
      "tensor([ 0.7264,  0.4645, -1.5722])\n",
      "tensor([ 0.7264,  0.4645, -1.5679])\n",
      "tensor([ 0.7264,  0.4645, -1.5635])\n",
      "tensor([ 0.7264,  0.4645, -1.5592])\n",
      "tensor([ 0.7264,  0.4645, -1.5549])\n",
      "tensor([ 0.7264,  0.4645, -1.5506])\n",
      "tensor([ 0.7264,  0.4645, -1.5463])\n",
      "tensor([ 0.7264,  0.4645, -1.5419])\n",
      "tensor([ 0.7264,  0.4645, -1.5376])\n",
      "tensor([ 0.7264,  0.4645, -1.5333])\n",
      "tensor([ 0.7264,  0.4645, -1.5290])\n",
      "tensor([ 0.7264,  0.4645, -1.5246])\n",
      "tensor([ 0.7264,  0.4645, -1.5203])\n",
      "tensor([ 0.7264,  0.4645, -1.5160])\n",
      "tensor([ 0.7264,  0.4645, -1.5117])\n",
      "tensor([ 0.7264,  0.4645, -1.5074])\n",
      "tensor([ 0.7264,  0.4645, -1.5030])\n",
      "tensor([ 0.7264,  0.4645, -1.4987])\n",
      "tensor([ 0.7264,  0.4645, -1.4944])\n",
      "tensor([ 0.7264,  0.4645, -1.4901])\n",
      "tensor([ 0.7264,  0.4645, -1.4858])\n",
      "tensor([ 0.7264,  0.4645, -1.4814])\n",
      "tensor([ 0.7264,  0.4645, -1.4771])\n",
      "tensor([ 0.7264,  0.4645, -1.4728])\n",
      "tensor([ 0.7264,  0.4645, -1.4685])\n",
      "tensor([ 0.7264,  0.4645, -1.4641])\n",
      "tensor([ 0.7264,  0.4645, -1.4598])\n",
      "tensor([ 0.7264,  0.4645, -1.4555])\n",
      "tensor([ 0.7264,  0.4645, -1.4512])\n",
      "tensor([ 0.7264,  0.4645, -1.4469])\n",
      "tensor([ 0.7264,  0.4645, -1.4425])\n",
      "tensor([ 0.7264,  0.4645, -1.4382])\n",
      "tensor([ 0.7264,  0.4645, -1.4339])\n",
      "tensor([ 0.7264,  0.4645, -1.4296])\n",
      "tensor([ 0.7264,  0.4645, -1.4253])\n",
      "tensor([ 0.7264,  0.4645, -1.4209])\n",
      "tensor([ 0.7264,  0.4645, -1.4166])\n",
      "tensor([ 0.7264,  0.4645, -1.4123])\n",
      "tensor([ 0.7264,  0.4645, -1.4080])\n",
      "tensor([ 0.7264,  0.4645, -1.4037])\n",
      "tensor([ 0.7264,  0.4645, -1.3993])\n",
      "tensor([ 0.7264,  0.4645, -1.3950])\n",
      "tensor([ 0.7264,  0.4645, -1.3907])\n",
      "tensor([ 0.7264,  0.4645, -1.3864])\n",
      "tensor([ 0.7264,  0.4645, -1.3820])\n",
      "tensor([ 0.7264,  0.4645, -1.3777])\n",
      "tensor([ 0.7264,  0.4645, -1.3734])\n",
      "tensor([ 0.7264,  0.4645, -1.3691])\n",
      "tensor([ 0.7264,  0.4645, -1.3648])\n",
      "tensor([ 0.7264,  0.4645, -1.3604])\n",
      "tensor([ 0.7264,  0.4645, -1.3561])\n",
      "tensor([ 0.7264,  0.4645, -1.3518])\n",
      "tensor([ 0.7264,  0.4645, -1.3475])\n",
      "tensor([ 0.7264,  0.4645, -1.3432])\n",
      "tensor([ 0.7264,  0.4645, -1.3388])\n",
      "tensor([ 0.7264,  0.4645, -1.3345])\n",
      "tensor([ 0.7264,  0.4645, -1.3302])\n",
      "tensor([ 0.7264,  0.4645, -1.3259])\n",
      "tensor([ 0.7264,  0.4645, -1.3215])\n",
      "tensor([ 0.7264,  0.4645, -1.3172])\n",
      "tensor([ 0.7264,  0.4645, -1.3129])\n",
      "tensor([ 0.7264,  0.4645, -1.3086])\n",
      "tensor([ 0.7264,  0.4645, -1.3043])\n",
      "tensor([ 0.7264,  0.4645, -1.2999])\n",
      "tensor([ 0.7264,  0.4645, -1.2956])\n",
      "tensor([ 0.7264,  0.4645, -1.2913])\n",
      "tensor([ 0.7264,  0.4645, -1.2870])\n",
      "tensor([ 0.7264,  0.4645, -1.2827])\n",
      "tensor([ 0.7264,  0.4645, -1.2783])\n",
      "tensor([ 0.7264,  0.4645, -1.2740])\n",
      "tensor([ 0.7264,  0.4645, -1.2697])\n",
      "tensor([ 0.7264,  0.4645, -1.2654])\n",
      "tensor([ 0.7264,  0.4645, -1.2610])\n",
      "tensor([ 0.7264,  0.4645, -1.2567])\n",
      "tensor([ 0.7264,  0.4645, -1.2524])\n",
      "tensor([ 0.7264,  0.4645, -1.2481])\n",
      "tensor([ 0.7264,  0.4645, -1.2438])\n",
      "tensor([ 0.7264,  0.4645, -1.2394])\n",
      "tensor([ 0.7264,  0.4645, -1.2351])\n",
      "tensor([ 0.7264,  0.4645, -1.2308])\n",
      "tensor([ 0.7264,  0.4645, -1.2265])\n",
      "tensor([ 0.7264,  0.4645, -1.2222])\n",
      "tensor([ 0.7264,  0.4645, -1.2178])\n",
      "tensor([ 0.7264,  0.4645, -1.2135])\n",
      "tensor([ 0.7264,  0.4645, -1.2092])\n",
      "tensor([ 0.7264,  0.4645, -1.2049])\n",
      "tensor([ 0.7264,  0.4645, -1.2005])\n",
      "tensor([ 0.7264,  0.4645, -1.1962])\n",
      "tensor([ 0.7264,  0.4645, -1.1919])\n",
      "tensor([ 0.7264,  0.4645, -1.1876])\n",
      "tensor([ 0.7264,  0.4645, -1.1833])\n",
      "tensor([ 0.7264,  0.4645, -1.1789])\n",
      "tensor([ 0.7264,  0.4645, -1.1746])\n",
      "tensor([ 0.7264,  0.4645, -1.1703])\n",
      "tensor([ 0.7264,  0.4645, -1.1660])\n",
      "tensor([ 0.7264,  0.4645, -1.1617])\n",
      "tensor([ 0.7264,  0.4645, -1.1573])\n",
      "tensor([ 0.7264,  0.4645, -1.1530])\n",
      "tensor([ 0.7264,  0.4645, -1.1487])\n",
      "tensor([ 0.7264,  0.4645, -1.1444])\n",
      "tensor([ 0.7264,  0.4645, -1.1400])\n",
      "tensor([ 0.7264,  0.4645, -1.1357])\n",
      "tensor([ 0.7264,  0.4645, -1.1314])\n",
      "tensor([ 0.7264,  0.4645, -1.1271])\n",
      "tensor([ 0.7264,  0.4645, -1.1228])\n",
      "tensor([ 0.7264,  0.4645, -1.1184])\n",
      "tensor([ 0.7264,  0.4645, -1.1141])\n",
      "tensor([ 0.7264,  0.4645, -1.1098])\n",
      "tensor([ 0.7264,  0.4645, -1.1055])\n",
      "tensor([ 0.7264,  0.4645, -1.1012])\n",
      "tensor([ 0.7264,  0.4645, -1.0968])\n",
      "tensor([ 0.7264,  0.4645, -1.0925])\n",
      "tensor([ 0.7264,  0.4645, -1.0882])\n",
      "tensor([ 0.7264,  0.4645, -1.0839])\n",
      "tensor([ 0.7264,  0.4645, -1.0795])\n",
      "tensor([ 0.7264,  0.4645, -1.0752])\n",
      "tensor([ 0.7264,  0.4645, -1.0709])\n",
      "tensor([ 0.7264,  0.4645, -1.0666])\n",
      "tensor([ 0.7264,  0.4645, -1.0623])\n",
      "tensor([ 0.7264,  0.4645, -1.0579])\n",
      "tensor([ 0.7264,  0.4645, -1.0536])\n",
      "tensor([ 0.7264,  0.4645, -1.0493])\n",
      "tensor([ 0.7264,  0.4645, -1.0450])\n",
      "tensor([ 0.7264,  0.4645, -1.0407])\n",
      "tensor([ 0.7264,  0.4645, -1.0363])\n",
      "tensor([ 0.7264,  0.4645, -1.0320])\n",
      "tensor([ 0.7264,  0.4645, -1.0277])\n",
      "tensor([ 0.7264,  0.4645, -1.0234])\n",
      "tensor([ 0.7264,  0.4645, -1.0190])\n",
      "tensor([ 0.7264,  0.4645, -1.0147])\n",
      "tensor([ 0.7264,  0.4645, -1.0104])\n",
      "tensor([ 0.7264,  0.4645, -1.0061])\n",
      "tensor([ 0.7264,  0.4645, -1.0018])\n",
      "tensor([ 0.7264,  0.4645, -0.9974])\n",
      "tensor([ 0.7264,  0.4645, -0.9931])\n",
      "tensor([ 0.7264,  0.4645, -0.9888])\n",
      "tensor([ 0.7264,  0.4645, -0.9845])\n",
      "tensor([ 0.7264,  0.4645, -0.9802])\n",
      "tensor([ 0.7264,  0.4645, -0.9758])\n",
      "tensor([ 0.7264,  0.4645, -0.9715])\n",
      "tensor([ 0.7264,  0.4645, -0.9672])\n",
      "tensor([ 0.7264,  0.4645, -0.9629])\n",
      "tensor([ 0.7264,  0.4645, -0.9585])\n",
      "tensor([ 0.7264,  0.4645, -0.9542])\n",
      "tensor([ 0.7264,  0.4645, -0.9499])\n",
      "tensor([ 0.7264,  0.4645, -0.9456])\n",
      "tensor([ 0.7264,  0.4645, -0.9413])\n",
      "tensor([ 0.7264,  0.4645, -0.9369])\n",
      "tensor([ 0.7264,  0.4645, -0.9326])\n",
      "tensor([ 0.7264,  0.4645, -0.9283])\n",
      "tensor([ 0.7264,  0.4645, -0.9240])\n",
      "tensor([ 0.7264,  0.4645, -0.9197])\n",
      "tensor([ 0.7264,  0.4645, -0.9153])\n",
      "tensor([ 0.7264,  0.4645, -0.9110])\n",
      "tensor([ 0.7264,  0.4645, -0.9067])\n",
      "tensor([ 0.7264,  0.4645, -0.9024])\n",
      "tensor([ 0.7264,  0.4645, -0.8980])\n",
      "tensor([ 0.7264,  0.4645, -0.8937])\n",
      "tensor([ 0.7264,  0.4645, -0.8894])\n",
      "tensor([ 0.7264,  0.4645, -0.8851])\n",
      "tensor([ 0.7264,  0.4645, -0.8808])\n",
      "tensor([ 0.7264,  0.4645, -0.8764])\n",
      "tensor([ 0.7264,  0.4645, -0.8721])\n",
      "tensor([ 0.7264,  0.4645, -0.8678])\n",
      "tensor([ 0.7264,  0.4645, -0.8635])\n",
      "tensor([ 0.7264,  0.4645, -0.8592])\n",
      "tensor([ 0.7264,  0.4645, -0.8548])\n",
      "tensor([ 0.7264,  0.4645, -0.8505])\n",
      "tensor([ 0.7264,  0.4645, -0.8462])\n",
      "tensor([ 0.7264,  0.4645, -0.8419])\n",
      "tensor([ 0.7264,  0.4645, -0.8376])\n",
      "tensor([ 0.7264,  0.4645, -0.8332])\n",
      "tensor([ 0.7264,  0.4645, -0.8289])\n",
      "tensor([ 0.7264,  0.4645, -0.8246])\n",
      "tensor([ 0.7264,  0.4645, -0.8203])\n",
      "tensor([ 0.7264,  0.4645, -0.8159])\n",
      "tensor([ 0.7264,  0.4645, -0.8116])\n",
      "tensor([ 0.7264,  0.4645, -0.8073])\n",
      "tensor([ 0.7264,  0.4645, -0.8030])\n",
      "tensor([ 0.7264,  0.4645, -0.7987])\n",
      "tensor([ 0.7264,  0.4645, -0.7943])\n",
      "tensor([ 0.7264,  0.4645, -0.7900])\n",
      "tensor([ 0.7264,  0.4645, -0.7857])\n",
      "tensor([ 0.7264,  0.4645, -0.7814])\n",
      "tensor([ 0.7264,  0.4645, -0.7771])\n",
      "tensor([ 0.7264,  0.4645, -0.7727])\n",
      "tensor([ 0.7264,  0.4645, -0.7684])\n",
      "tensor([ 0.7264,  0.4645, -0.7641])\n",
      "tensor([ 0.7264,  0.4645, -0.7598])\n",
      "tensor([ 0.7264,  0.4645, -0.7554])\n",
      "tensor([ 0.7264,  0.4645, -0.7511])\n",
      "tensor([ 0.7264,  0.4645, -0.7468])\n",
      "tensor([ 0.7264,  0.4645, -0.7425])\n",
      "tensor([ 0.7264,  0.4645, -0.7382])\n",
      "tensor([ 0.7264,  0.4645, -0.7338])\n",
      "tensor([ 0.7264,  0.4645, -0.7295])\n",
      "tensor([ 0.7264,  0.4645, -0.7252])\n",
      "tensor([ 0.7264,  0.4645, -0.7209])\n",
      "tensor([ 0.7264,  0.4645, -0.7166])\n",
      "tensor([ 0.7264,  0.4645, -0.7122])\n",
      "tensor([ 0.7264,  0.4645, -0.7079])\n",
      "tensor([ 0.7264,  0.4645, -0.7036])\n",
      "tensor([ 0.7264,  0.4645, -0.6993])\n",
      "tensor([ 0.7264,  0.4645, -0.6949])\n",
      "tensor([ 0.7264,  0.4645, -0.6906])\n",
      "tensor([ 0.7264,  0.4645, -0.6863])\n",
      "tensor([ 0.7264,  0.4645, -0.6820])\n",
      "tensor([ 0.7264,  0.4645, -0.6777])\n",
      "tensor([ 0.7264,  0.4645, -0.6733])\n",
      "tensor([ 0.7264,  0.4645, -0.6690])\n",
      "tensor([ 0.7264,  0.4645, -0.6647])\n",
      "tensor([ 0.7264,  0.4645, -0.6604])\n",
      "tensor([ 0.7264,  0.4645, -0.6561])\n",
      "tensor([ 0.7264,  0.4645, -0.6517])\n",
      "tensor([ 0.7264,  0.4645, -0.6474])\n",
      "tensor([ 0.7264,  0.4645, -0.6431])\n",
      "tensor([ 0.7264,  0.4645, -0.6388])\n",
      "tensor([ 0.7264,  0.4645, -0.6344])\n",
      "tensor([ 0.7264,  0.4645, -0.6301])\n",
      "tensor([ 0.7264,  0.4645, -0.6258])\n",
      "tensor([ 0.7264,  0.4645, -0.6215])\n",
      "tensor([ 0.7264,  0.4645, -0.6172])\n",
      "tensor([ 0.7264,  0.4645, -0.6128])\n",
      "tensor([ 0.7264,  0.4645, -0.6085])\n",
      "tensor([ 0.7264,  0.4645, -0.6042])\n",
      "tensor([ 0.7264,  0.4645, -0.5999])\n",
      "tensor([ 0.7264,  0.4645, -0.5956])\n",
      "tensor([ 0.7264,  0.4645, -0.5912])\n",
      "tensor([ 0.7264,  0.4645, -0.5869])\n",
      "tensor([ 0.7264,  0.4645, -0.5826])\n",
      "tensor([ 0.7264,  0.4645, -0.5783])\n",
      "tensor([ 0.7264,  0.4645, -0.5739])\n",
      "tensor([ 0.7264,  0.4645, -0.5696])\n",
      "tensor([ 0.7264,  0.4645, -0.5653])\n",
      "tensor([ 0.7264,  0.4645, -0.5610])\n",
      "tensor([ 0.7264,  0.4645, -0.5567])\n",
      "tensor([ 0.7264,  0.4645, -0.5523])\n",
      "tensor([ 0.7264,  0.4645, -0.5480])\n",
      "tensor([ 0.7264,  0.4645, -0.5437])\n",
      "tensor([ 0.7264,  0.4645, -0.5394])\n",
      "tensor([ 0.7264,  0.4645, -0.5351])\n",
      "tensor([ 0.7264,  0.4645, -0.5307])\n",
      "tensor([ 0.7264,  0.4645, -0.5264])\n",
      "tensor([ 0.7264,  0.4645, -0.5221])\n",
      "tensor([ 0.7264,  0.4645, -0.5178])\n",
      "tensor([ 0.7264,  0.4645, -0.5134])\n",
      "tensor([ 0.7264,  0.4645, -0.5091])\n",
      "tensor([ 0.7264,  0.4645, -0.5048])\n",
      "tensor([ 0.7264,  0.4645, -0.5005])\n",
      "tensor([ 0.7264,  0.4645, -0.4962])\n",
      "tensor([ 0.7264,  0.4645, -0.4918])\n",
      "tensor([ 0.7264,  0.4645, -0.4875])\n",
      "tensor([ 0.7264,  0.4645, -0.4832])\n",
      "tensor([ 0.7264,  0.4645, -0.4789])\n",
      "tensor([ 0.7264,  0.4645, -0.4746])\n",
      "tensor([ 0.7264,  0.4645, -0.4702])\n",
      "tensor([ 0.7264,  0.4645, -0.4659])\n",
      "tensor([ 0.7264,  0.4645, -0.4616])\n",
      "tensor([ 0.7264,  0.4645, -0.4573])\n",
      "tensor([ 0.7264,  0.4645, -0.4529])\n",
      "tensor([ 0.7264,  0.4645, -0.4486])\n",
      "tensor([ 0.7264,  0.4645, -0.4443])\n",
      "tensor([ 0.7264,  0.4645, -0.4400])\n",
      "tensor([ 0.7264,  0.4645, -0.4357])\n",
      "tensor([ 0.7264,  0.4645, -0.4313])\n",
      "tensor([ 0.7264,  0.4645, -0.4270])\n",
      "tensor([ 0.7264,  0.4645, -0.4227])\n",
      "tensor([ 0.7264,  0.4645, -0.4184])\n",
      "tensor([ 0.7264,  0.4645, -0.4141])\n",
      "tensor([ 0.7264,  0.4645, -0.4097])\n",
      "tensor([ 0.7264,  0.4645, -0.4054])\n",
      "tensor([ 0.7264,  0.4645, -0.4011])\n",
      "tensor([ 0.7264,  0.4645, -0.3968])\n",
      "tensor([ 0.7264,  0.4645, -0.3924])\n",
      "tensor([ 0.7264,  0.4645, -0.3881])\n",
      "tensor([ 0.7264,  0.4645, -0.3838])\n",
      "tensor([ 0.7264,  0.4645, -0.3795])\n",
      "tensor([ 0.7264,  0.4645, -0.3752])\n",
      "tensor([ 0.7264,  0.4645, -0.3708])\n",
      "tensor([ 0.7264,  0.4645, -0.3665])\n",
      "tensor([ 0.7264,  0.4645, -0.3622])\n",
      "tensor([ 0.7264,  0.4645, -0.3579])\n",
      "tensor([ 0.7264,  0.4645, -0.3536])\n",
      "tensor([ 0.7264,  0.4645, -0.3492])\n",
      "tensor([ 0.7264,  0.4645, -0.3449])\n",
      "tensor([ 0.7264,  0.4645, -0.3406])\n",
      "tensor([ 0.7264,  0.4645, -0.3363])\n",
      "tensor([ 0.7264,  0.4645, -0.3319])\n",
      "tensor([ 0.7264,  0.4645, -0.3276])\n",
      "tensor([ 0.7264,  0.4645, -0.3233])\n",
      "tensor([ 0.7264,  0.4645, -0.3190])\n",
      "tensor([ 0.7264,  0.4645, -0.3147])\n",
      "tensor([ 0.7264,  0.4645, -0.3103])\n",
      "tensor([ 0.7264,  0.4645, -0.3060])\n",
      "tensor([ 0.7264,  0.4645, -0.3017])\n",
      "tensor([ 0.7264,  0.4645, -0.2974])\n",
      "tensor([ 0.7264,  0.4645, -0.2931])\n",
      "tensor([ 0.7264,  0.4645, -0.2887])\n",
      "tensor([ 0.7264,  0.4645, -0.2844])\n",
      "tensor([ 0.7264,  0.4645, -0.2801])\n",
      "tensor([ 0.7264,  0.4645, -0.2758])\n",
      "tensor([ 0.7264,  0.4645, -0.2715])\n",
      "tensor([ 0.7264,  0.4645, -0.2671])\n",
      "tensor([ 0.7264,  0.4645, -0.2628])\n",
      "tensor([ 0.7264,  0.4645, -0.2585])\n",
      "tensor([ 0.7264,  0.4645, -0.2542])\n",
      "tensor([ 0.7264,  0.4645, -0.2498])\n",
      "tensor([ 0.7264,  0.4645, -0.2455])\n",
      "tensor([ 0.7264,  0.4645, -0.2412])\n",
      "tensor([ 0.7264,  0.4645, -0.2369])\n",
      "tensor([ 0.7264,  0.4645, -0.2326])\n",
      "tensor([ 0.7264,  0.4645, -0.2282])\n",
      "tensor([ 0.7264,  0.4645, -0.2239])\n",
      "tensor([ 0.7264,  0.4645, -0.2196])\n",
      "tensor([ 0.7264,  0.4645, -0.2153])\n",
      "tensor([ 0.7264,  0.4645, -0.2110])\n",
      "tensor([ 0.7264,  0.4645, -0.2066])\n",
      "tensor([ 0.7264,  0.4645, -0.2023])\n",
      "tensor([ 0.7264,  0.4645, -0.1980])\n",
      "tensor([ 0.7264,  0.4645, -0.1937])\n",
      "tensor([ 0.7264,  0.4645, -0.1893])\n",
      "tensor([ 0.7264,  0.4645, -0.1850])\n",
      "tensor([ 0.7264,  0.4645, -0.1807])\n",
      "tensor([ 0.7264,  0.4645, -0.1764])\n",
      "tensor([ 0.7264,  0.4645, -0.1721])\n",
      "tensor([ 0.7264,  0.4645, -0.1677])\n",
      "tensor([ 0.7264,  0.4645, -0.1634])\n",
      "tensor([ 0.7264,  0.4645, -0.1591])\n",
      "tensor([ 0.7264,  0.4645, -0.1548])\n",
      "tensor([ 0.7264,  0.4645, -0.1505])\n",
      "tensor([ 0.7264,  0.4645, -0.1461])\n",
      "tensor([ 0.7264,  0.4645, -0.1418])\n",
      "tensor([ 0.7264,  0.4645, -0.1375])\n",
      "tensor([ 0.7264,  0.4645, -0.1332])\n",
      "tensor([ 0.7264,  0.4645, -0.1288])\n",
      "tensor([ 0.7264,  0.4645, -0.1245])\n",
      "tensor([ 0.7264,  0.4645, -0.1202])\n",
      "tensor([ 0.7264,  0.4645, -0.1159])\n",
      "tensor([ 0.7264,  0.4645, -0.1116])\n",
      "tensor([ 0.7264,  0.4645, -0.1072])\n",
      "tensor([ 0.7264,  0.4645, -0.1029])\n",
      "tensor([ 0.7264,  0.4645, -0.0986])\n",
      "tensor([ 0.7264,  0.4645, -0.0943])\n",
      "tensor([ 0.7264,  0.4645, -0.0900])\n",
      "tensor([ 0.7264,  0.4645, -0.0856])\n",
      "tensor([ 0.7264,  0.4645, -0.0813])\n",
      "tensor([ 0.7264,  0.4645, -0.0770])\n",
      "tensor([ 0.7264,  0.4645, -0.0727])\n",
      "tensor([ 0.7264,  0.4645, -0.0683])\n",
      "tensor([ 0.7264,  0.4645, -0.0640])\n",
      "tensor([ 0.7264,  0.4645, -0.0597])\n",
      "tensor([ 0.7264,  0.4645, -0.0554])\n",
      "tensor([ 0.7264,  0.4645, -0.0511])\n",
      "tensor([ 0.7264,  0.4645, -0.0467])\n",
      "tensor([ 0.7264,  0.4645, -0.0424])\n",
      "tensor([ 0.7264,  0.4645, -0.0381])\n",
      "tensor([ 0.7264,  0.4645, -0.0338])\n",
      "tensor([ 0.7264,  0.4645, -0.0295])\n",
      "tensor([ 0.7264,  0.4645, -0.0251])\n",
      "tensor([ 0.7264,  0.4645, -0.0208])\n",
      "tensor([ 0.7264,  0.4645, -0.0165])\n",
      "tensor([ 0.7264,  0.4645, -0.0122])\n",
      "tensor([ 0.7264,  0.4645, -0.0078])\n",
      "tensor([ 0.7264,  0.4645, -0.0035])\n",
      "tensor([0.7264, 0.4645, 0.0008])\n",
      "tensor([0.7264, 0.4645, 0.0051])\n",
      "tensor([0.7264, 0.4645, 0.0094])\n",
      "tensor([0.7264, 0.4645, 0.0138])\n",
      "tensor([0.7264, 0.4645, 0.0181])\n",
      "tensor([0.7264, 0.4645, 0.0224])\n",
      "tensor([0.7264, 0.4645, 0.0267])\n",
      "tensor([0.7264, 0.4645, 0.0310])\n",
      "tensor([0.7264, 0.4645, 0.0354])\n",
      "tensor([0.7264, 0.4645, 0.0397])\n",
      "tensor([0.7264, 0.4645, 0.0440])\n",
      "tensor([0.7264, 0.4645, 0.0483])\n",
      "tensor([0.7264, 0.4645, 0.0527])\n",
      "tensor([0.7264, 0.4645, 0.0570])\n",
      "tensor([0.7264, 0.4645, 0.0613])\n",
      "tensor([0.7264, 0.4645, 0.0656])\n",
      "tensor([0.7264, 0.4645, 0.0699])\n",
      "tensor([0.7264, 0.4645, 0.0743])\n",
      "tensor([0.7264, 0.4645, 0.0786])\n",
      "tensor([0.7264, 0.4645, 0.0829])\n",
      "tensor([0.7264, 0.4645, 0.0872])\n",
      "tensor([0.7264, 0.4645, 0.0915])\n",
      "tensor([0.7264, 0.4645, 0.0959])\n",
      "tensor([0.7264, 0.4645, 0.1002])\n",
      "tensor([0.7264, 0.4645, 0.1045])\n",
      "tensor([0.7264, 0.4645, 0.1088])\n",
      "tensor([0.7264, 0.4645, 0.1132])\n",
      "tensor([0.7264, 0.4645, 0.1175])\n",
      "tensor([0.7264, 0.4645, 0.1218])\n",
      "tensor([0.7264, 0.4645, 0.1261])\n",
      "tensor([0.7264, 0.4645, 0.1304])\n",
      "tensor([0.7264, 0.4645, 0.1348])\n",
      "tensor([0.7264, 0.4645, 0.1391])\n",
      "tensor([0.7264, 0.4645, 0.1434])\n",
      "tensor([0.7264, 0.4645, 0.1477])\n",
      "tensor([0.7264, 0.4645, 0.1520])\n",
      "tensor([0.7264, 0.4645, 0.1564])\n",
      "tensor([0.7264, 0.4645, 0.1607])\n",
      "tensor([0.7264, 0.4645, 0.1650])\n",
      "tensor([0.7264, 0.4645, 0.1693])\n",
      "tensor([0.7264, 0.4645, 0.1737])\n",
      "tensor([0.7264, 0.4645, 0.1780])\n",
      "tensor([0.7264, 0.4645, 0.1823])\n",
      "tensor([0.7264, 0.4645, 0.1866])\n",
      "tensor([0.7264, 0.4645, 0.1909])\n",
      "tensor([0.7264, 0.4645, 0.1953])\n",
      "tensor([0.7264, 0.4645, 0.1996])\n",
      "tensor([0.7264, 0.4645, 0.2039])\n",
      "tensor([0.7264, 0.4645, 0.2082])\n",
      "tensor([0.7264, 0.4645, 0.2125])\n",
      "tensor([0.7264, 0.4645, 0.2169])\n",
      "tensor([0.7264, 0.4645, 0.2212])\n",
      "tensor([0.7264, 0.4645, 0.2255])\n",
      "tensor([0.7264, 0.4645, 0.2298])\n",
      "tensor([0.7264, 0.4645, 0.2342])\n",
      "tensor([0.7264, 0.4645, 0.2385])\n",
      "tensor([0.7264, 0.4645, 0.2428])\n",
      "tensor([0.7264, 0.4645, 0.2471])\n",
      "tensor([0.7264, 0.4645, 0.2514])\n",
      "tensor([0.7264, 0.4645, 0.2558])\n",
      "tensor([0.7264, 0.4645, 0.2601])\n",
      "tensor([0.7264, 0.4645, 0.2644])\n",
      "tensor([0.7264, 0.4645, 0.2687])\n",
      "tensor([0.7264, 0.4645, 0.2730])\n",
      "tensor([0.7264, 0.4645, 0.2774])\n",
      "tensor([0.7264, 0.4645, 0.2817])\n",
      "tensor([0.7264, 0.4645, 0.2860])\n",
      "tensor([0.7264, 0.4645, 0.2903])\n",
      "tensor([0.7264, 0.4645, 0.2946])\n",
      "tensor([0.7264, 0.4645, 0.2990])\n",
      "tensor([0.7264, 0.4645, 0.3033])\n",
      "tensor([0.7264, 0.4645, 0.3076])\n",
      "tensor([0.7264, 0.4645, 0.3119])\n",
      "tensor([0.7264, 0.4645, 0.3163])\n",
      "tensor([0.7264, 0.4645, 0.3206])\n",
      "tensor([0.7264, 0.4645, 0.3249])\n",
      "tensor([0.7264, 0.4645, 0.3292])\n",
      "tensor([0.7264, 0.4645, 0.3335])\n",
      "tensor([0.7264, 0.4645, 0.3379])\n",
      "tensor([0.7264, 0.4645, 0.3422])\n",
      "tensor([0.7264, 0.4645, 0.3465])\n",
      "tensor([0.7264, 0.4645, 0.3508])\n",
      "tensor([0.7264, 0.4645, 0.3551])\n",
      "tensor([0.7264, 0.4645, 0.3595])\n",
      "tensor([0.7264, 0.4645, 0.3638])\n",
      "tensor([0.7264, 0.4645, 0.3681])\n",
      "tensor([0.7264, 0.4645, 0.3724])\n",
      "tensor([0.7264, 0.4645, 0.3768])\n",
      "tensor([0.7264, 0.4645, 0.3811])\n",
      "tensor([0.7264, 0.4645, 0.3854])\n",
      "tensor([0.7264, 0.4645, 0.3897])\n",
      "tensor([0.7264, 0.4645, 0.3940])\n",
      "tensor([0.7264, 0.4645, 0.3984])\n",
      "tensor([0.7264, 0.4645, 0.4027])\n",
      "tensor([0.7264, 0.4645, 0.4070])\n",
      "tensor([0.7264, 0.4645, 0.4113])\n",
      "tensor([0.7264, 0.4645, 0.4156])\n",
      "tensor([0.7264, 0.4645, 0.4200])\n",
      "tensor([0.7264, 0.4645, 0.4243])\n",
      "tensor([0.7264, 0.4645, 0.4286])\n",
      "tensor([0.7264, 0.4645, 0.4329])\n",
      "tensor([0.7264, 0.4645, 0.4373])\n",
      "tensor([0.7264, 0.4645, 0.4416])\n",
      "tensor([0.7264, 0.4645, 0.4459])\n",
      "tensor([0.7264, 0.4645, 0.4502])\n",
      "tensor([0.7264, 0.4645, 0.4545])\n",
      "tensor([0.7264, 0.4645, 0.4589])\n",
      "tensor([0.7264, 0.4645, 0.4632])\n",
      "tensor([0.7264, 0.4645, 0.4675])\n",
      "tensor([0.7264, 0.4645, 0.4718])\n",
      "tensor([0.7264, 0.4645, 0.4761])\n",
      "tensor([0.7264, 0.4645, 0.4805])\n",
      "tensor([0.7264, 0.4645, 0.4848])\n",
      "tensor([0.7264, 0.4645, 0.4891])\n",
      "tensor([0.7264, 0.4645, 0.4934])\n",
      "tensor([0.7264, 0.4645, 0.4978])\n",
      "tensor([0.7264, 0.4645, 0.5021])\n",
      "tensor([0.7264, 0.4645, 0.5064])\n",
      "tensor([0.7264, 0.4645, 0.5107])\n",
      "tensor([0.7264, 0.4645, 0.5150])\n",
      "tensor([0.7264, 0.4645, 0.5194])\n",
      "tensor([0.7264, 0.4645, 0.5237])\n",
      "tensor([0.7264, 0.4645, 0.5280])\n",
      "tensor([0.7264, 0.4645, 0.5323])\n",
      "tensor([0.7264, 0.4645, 0.5366])\n",
      "tensor([0.7264, 0.4645, 0.5410])\n",
      "tensor([0.7264, 0.4645, 0.5453])\n",
      "tensor([0.7264, 0.4645, 0.5496])\n",
      "tensor([0.7264, 0.4645, 0.5539])\n",
      "tensor([0.7264, 0.4645, 0.5583])\n",
      "tensor([0.7264, 0.4645, 0.5626])\n",
      "tensor([0.7264, 0.4645, 0.5669])\n",
      "tensor([0.7264, 0.4645, 0.5712])\n",
      "tensor([0.7264, 0.4645, 0.5755])\n",
      "tensor([0.7264, 0.4645, 0.5799])\n",
      "tensor([0.7264, 0.4645, 0.5842])\n",
      "tensor([0.7264, 0.4645, 0.5885])\n",
      "tensor([0.7264, 0.4645, 0.5928])\n",
      "tensor([0.7264, 0.4645, 0.5971])\n",
      "tensor([0.7264, 0.4645, 0.6015])\n",
      "tensor([0.7264, 0.4645, 0.6058])\n",
      "tensor([0.7264, 0.4645, 0.6101])\n",
      "tensor([0.7264, 0.4645, 0.6144])\n",
      "tensor([0.7264, 0.4645, 0.6188])\n",
      "tensor([0.7264, 0.4645, 0.6231])\n",
      "tensor([0.7264, 0.4645, 0.6274])\n",
      "tensor([0.7264, 0.4645, 0.6317])\n",
      "tensor([0.7264, 0.4645, 0.6360])\n",
      "tensor([0.7264, 0.4645, 0.6404])\n",
      "tensor([0.7264, 0.4645, 0.6447])\n",
      "tensor([0.7264, 0.4645, 0.6490])\n",
      "tensor([0.7264, 0.4645, 0.6533])\n",
      "tensor([0.7264, 0.4645, 0.6576])\n",
      "tensor([0.7264, 0.4645, 0.6620])\n",
      "tensor([0.7264, 0.4645, 0.6663])\n",
      "tensor([0.7264, 0.4645, 0.6706])\n",
      "tensor([0.7264, 0.4645, 0.6749])\n",
      "tensor([0.7264, 0.4645, 0.6793])\n",
      "tensor([0.7264, 0.4645, 0.6836])\n",
      "tensor([0.7264, 0.4645, 0.6879])\n",
      "tensor([0.7264, 0.4645, 0.6922])\n",
      "tensor([0.7264, 0.4645, 0.6965])\n",
      "tensor([0.7264, 0.4645, 0.7009])\n",
      "tensor([0.7264, 0.4645, 0.7052])\n",
      "tensor([0.7264, 0.4645, 0.7095])\n",
      "tensor([0.7264, 0.4645, 0.7138])\n",
      "tensor([0.7264, 0.4645, 0.7181])\n",
      "tensor([0.7264, 0.4645, 0.7225])\n",
      "tensor([0.7264, 0.4645, 0.7268])\n",
      "tensor([0.7264, 0.4645, 0.7311])\n",
      "tensor([0.7264, 0.4645, 0.7354])\n",
      "tensor([0.7264, 0.4645, 0.7398])\n",
      "tensor([0.7264, 0.4645, 0.7441])\n",
      "tensor([0.7264, 0.4645, 0.7484])\n",
      "tensor([0.7264, 0.4645, 0.7527])\n",
      "tensor([0.7264, 0.4645, 0.7570])\n",
      "tensor([0.7264, 0.4645, 0.7614])\n",
      "tensor([0.7264, 0.4645, 0.7657])\n",
      "tensor([0.7264, 0.4645, 0.7700])\n",
      "tensor([0.7264, 0.4645, 0.7743])\n",
      "tensor([0.7264, 0.4645, 0.7786])\n",
      "tensor([0.7264, 0.4645, 0.7830])\n",
      "tensor([0.7264, 0.4645, 0.7873])\n",
      "tensor([0.7264, 0.4645, 0.7916])\n",
      "tensor([0.7264, 0.4645, 0.7959])\n",
      "tensor([0.7264, 0.4645, 0.8003])\n",
      "tensor([0.7264, 0.4645, 0.8046])\n",
      "tensor([0.7264, 0.4645, 0.8089])\n",
      "tensor([0.7264, 0.4645, 0.8132])\n",
      "tensor([0.7264, 0.4645, 0.8175])\n",
      "tensor([0.7264, 0.4645, 0.8219])\n",
      "tensor([0.7264, 0.4645, 0.8262])\n",
      "tensor([0.7264, 0.4645, 0.8305])\n",
      "tensor([0.7264, 0.4645, 0.8348])\n",
      "tensor([0.7264, 0.4645, 0.8391])\n",
      "tensor([0.7264, 0.4645, 0.8435])\n",
      "tensor([0.7264, 0.4645, 0.8478])\n",
      "tensor([0.7264, 0.4645, 0.8521])\n",
      "tensor([0.7264, 0.4645, 0.8564])\n",
      "tensor([0.7264, 0.4645, 0.8607])\n",
      "tensor([0.7264, 0.4645, 0.8651])\n",
      "tensor([0.7264, 0.4645, 0.8694])\n",
      "tensor([0.7264, 0.4645, 0.8737])\n",
      "tensor([0.7264, 0.4645, 0.8780])\n",
      "tensor([0.7264, 0.4645, 0.8824])\n",
      "tensor([0.7264, 0.4645, 0.8867])\n",
      "tensor([0.7264, 0.4645, 0.8910])\n",
      "tensor([0.7264, 0.4645, 0.8953])\n",
      "tensor([0.7264, 0.4645, 0.8996])\n",
      "tensor([0.7264, 0.4645, 0.9040])\n",
      "tensor([0.7264, 0.4645, 0.9083])\n",
      "tensor([0.7264, 0.4645, 0.9126])\n",
      "tensor([0.7264, 0.4645, 0.9169])\n",
      "tensor([0.7264, 0.4645, 0.9212])\n",
      "tensor([0.7264, 0.4645, 0.9256])\n",
      "tensor([0.7264, 0.4645, 0.9299])\n",
      "tensor([0.7264, 0.4645, 0.9342])\n",
      "tensor([0.7264, 0.4645, 0.9385])\n",
      "tensor([0.7264, 0.4645, 0.9429])\n",
      "tensor([0.7264, 0.4645, 0.9472])\n",
      "tensor([0.7264, 0.4645, 0.9515])\n",
      "tensor([0.7264, 0.4645, 0.9558])\n",
      "tensor([0.7264, 0.4645, 0.9601])\n",
      "tensor([0.7264, 0.4645, 0.9645])\n",
      "tensor([0.7264, 0.4645, 0.9688])\n",
      "tensor([0.7264, 0.4645, 0.9731])\n",
      "tensor([0.7264, 0.4645, 0.9774])\n",
      "tensor([0.7264, 0.4645, 0.9817])\n",
      "tensor([0.7264, 0.4645, 0.9861])\n",
      "tensor([0.7264, 0.4645, 0.9904])\n",
      "tensor([0.7264, 0.4645, 0.9947])\n",
      "tensor([0.7264, 0.4645, 0.9990])\n",
      "tensor([0.7264, 0.4645, 1.0034])\n",
      "tensor([0.7264, 0.4645, 1.0077])\n",
      "tensor([0.7264, 0.4645, 1.0120])\n",
      "tensor([0.7264, 0.4645, 1.0163])\n",
      "tensor([0.7264, 0.4645, 1.0206])\n",
      "tensor([0.7264, 0.4645, 1.0250])\n",
      "tensor([0.7264, 0.4645, 1.0293])\n",
      "tensor([0.7264, 0.4645, 1.0336])\n",
      "tensor([0.7264, 0.4645, 1.0379])\n",
      "tensor([0.7264, 0.4645, 1.0422])\n",
      "tensor([0.7264, 0.4645, 1.0466])\n",
      "tensor([0.7264, 0.4645, 1.0509])\n",
      "tensor([0.7264, 0.4645, 1.0552])\n",
      "tensor([0.7264, 0.4645, 1.0595])\n",
      "tensor([0.7264, 0.4645, 1.0639])\n",
      "tensor([0.7264, 0.4645, 1.0682])\n",
      "tensor([0.7264, 0.4645, 1.0725])\n",
      "tensor([0.7264, 0.4645, 1.0768])\n",
      "tensor([0.7264, 0.4645, 1.0811])\n",
      "tensor([0.7264, 0.4645, 1.0855])\n",
      "tensor([0.7264, 0.4645, 1.0898])\n",
      "tensor([0.7264, 0.4645, 1.0941])\n",
      "tensor([0.7264, 0.4645, 1.0984])\n",
      "tensor([0.7264, 0.4645, 1.1027])\n",
      "tensor([0.7264, 0.4645, 1.1071])\n",
      "tensor([0.7264, 0.4645, 1.1114])\n",
      "tensor([0.7264, 0.4645, 1.1157])\n",
      "tensor([0.7264, 0.4645, 1.1200])\n",
      "tensor([0.7264, 0.4645, 1.1244])\n",
      "tensor([0.7264, 0.4645, 1.1287])\n",
      "tensor([0.7264, 0.4645, 1.1330])\n",
      "tensor([0.7264, 0.4645, 1.1373])\n",
      "tensor([0.7264, 0.4645, 1.1416])\n",
      "tensor([0.7264, 0.4645, 1.1460])\n",
      "tensor([0.7264, 0.4645, 1.1503])\n",
      "tensor([0.7264, 0.4645, 1.1546])\n",
      "tensor([0.7264, 0.4645, 1.1589])\n",
      "tensor([0.7264, 0.4645, 1.1632])\n",
      "tensor([0.7264, 0.4645, 1.1676])\n",
      "tensor([0.7264, 0.4645, 1.1719])\n",
      "tensor([0.7264, 0.4645, 1.1762])\n",
      "tensor([0.7264, 0.4645, 1.1805])\n",
      "tensor([0.7264, 0.4645, 1.1849])\n",
      "tensor([0.7264, 0.4645, 1.1892])\n",
      "tensor([0.7264, 0.4645, 1.1935])\n",
      "tensor([0.7264, 0.4645, 1.1978])\n",
      "tensor([0.7264, 0.4645, 1.2021])\n",
      "tensor([0.7264, 0.4645, 1.2065])\n",
      "tensor([0.7264, 0.4645, 1.2108])\n",
      "tensor([0.7264, 0.4645, 1.2151])\n",
      "tensor([0.7264, 0.4645, 1.2194])\n",
      "tensor([0.7264, 0.4645, 1.2237])\n",
      "tensor([0.7264, 0.4645, 1.2281])\n",
      "tensor([0.7264, 0.4645, 1.2324])\n",
      "tensor([0.7264, 0.4645, 1.2367])\n",
      "tensor([0.7264, 0.4645, 1.2410])\n",
      "tensor([0.7264, 0.4645, 1.2454])\n",
      "tensor([0.7264, 0.4645, 1.2497])\n",
      "tensor([0.7264, 0.4645, 1.2540])\n",
      "tensor([0.7264, 0.4645, 1.2583])\n",
      "tensor([0.7264, 0.4645, 1.2626])\n",
      "tensor([0.7264, 0.4645, 1.2670])\n",
      "tensor([0.7264, 0.4645, 1.2713])\n",
      "tensor([0.7264, 0.4645, 1.2756])\n",
      "tensor([0.7264, 0.4645, 1.2799])\n",
      "tensor([0.7264, 0.4645, 1.2842])\n",
      "tensor([0.7264, 0.4645, 1.2886])\n",
      "tensor([0.7264, 0.4645, 1.2929])\n",
      "tensor([0.7264, 0.4645, 1.2972])\n",
      "tensor([0.7264, 0.4645, 1.3015])\n",
      "tensor([0.7264, 0.4645, 1.3059])\n",
      "tensor([0.7264, 0.4645, 1.3102])\n",
      "tensor([0.7264, 0.4645, 1.3145])\n",
      "tensor([0.7264, 0.4645, 1.3188])\n",
      "tensor([0.7264, 0.4645, 1.3231])\n",
      "tensor([0.7264, 0.4645, 1.3275])\n",
      "tensor([0.7264, 0.4645, 1.3318])\n",
      "tensor([0.7264, 0.4645, 1.3361])\n",
      "tensor([0.7264, 0.4645, 1.3404])\n",
      "tensor([0.7264, 0.4645, 1.3447])\n",
      "tensor([0.7264, 0.4645, 1.3491])\n",
      "tensor([0.7264, 0.4645, 1.3534])\n",
      "tensor([0.7264, 0.4645, 1.3577])\n",
      "tensor([0.7264, 0.4645, 1.3620])\n",
      "tensor([0.7264, 0.4645, 1.3664])\n",
      "tensor([0.7264, 0.4645, 1.3707])\n",
      "tensor([0.7264, 0.4645, 1.3750])\n",
      "tensor([0.7264, 0.4645, 1.3793])\n",
      "tensor([0.7264, 0.4645, 1.3836])\n",
      "tensor([0.7264, 0.4645, 1.3880])\n",
      "tensor([0.7264, 0.4645, 1.3923])\n",
      "tensor([0.7264, 0.4645, 1.3966])\n",
      "tensor([0.7264, 0.4645, 1.4009])\n",
      "tensor([0.7264, 0.4645, 1.4052])\n",
      "tensor([0.7264, 0.4645, 1.4096])\n",
      "tensor([0.7264, 0.4645, 1.4139])\n",
      "tensor([0.7264, 0.4645, 1.4182])\n",
      "tensor([0.7264, 0.4645, 1.4225])\n",
      "tensor([0.7264, 0.4645, 1.4268])\n",
      "tensor([0.7264, 0.4645, 1.4312])\n",
      "tensor([0.7264, 0.4645, 1.4355])\n",
      "tensor([0.7264, 0.4645, 1.4398])\n",
      "tensor([0.7264, 0.4645, 1.4441])\n",
      "tensor([0.7264, 0.4645, 1.4485])\n",
      "tensor([0.7264, 0.4645, 1.4528])\n",
      "tensor([0.7264, 0.4645, 1.4571])\n",
      "tensor([0.7264, 0.4645, 1.4614])\n",
      "tensor([0.7264, 0.4645, 1.4657])\n",
      "tensor([0.7264, 0.4645, 1.4701])\n",
      "tensor([0.7264, 0.4645, 1.4744])\n",
      "tensor([0.7264, 0.4645, 1.4787])\n",
      "tensor([0.7264, 0.4645, 1.4830])\n",
      "tensor([0.7264, 0.4645, 1.4873])\n",
      "tensor([0.7264, 0.4645, 1.4917])\n",
      "tensor([0.7264, 0.4645, 1.4960])\n",
      "tensor([0.7264, 0.4645, 1.5003])\n",
      "tensor([0.7264, 0.4645, 1.5046])\n",
      "tensor([0.7264, 0.4645, 1.5090])\n",
      "tensor([0.7264, 0.4645, 1.5133])\n",
      "tensor([0.7264, 0.4645, 1.5176])\n",
      "tensor([0.7264, 0.4645, 1.5219])\n",
      "tensor([0.7264, 0.4645, 1.5262])\n",
      "tensor([0.7264, 0.4645, 1.5306])\n",
      "tensor([0.7264, 0.4645, 1.5349])\n",
      "tensor([0.7264, 0.4645, 1.5392])\n",
      "tensor([0.7264, 0.4645, 1.5435])\n",
      "tensor([0.7264, 0.4645, 1.5478])\n",
      "tensor([0.7264, 0.4645, 1.5522])\n",
      "tensor([0.7264, 0.4645, 1.5565])\n",
      "tensor([0.7264, 0.4645, 1.5608])\n",
      "tensor([0.7264, 0.4645, 1.5651])\n",
      "tensor([0.7264, 0.4645, 1.5695])\n",
      "tensor([0.7264, 0.4645, 1.5738])\n",
      "tensor([0.7264, 0.4645, 1.5781])\n",
      "tensor([0.7264, 0.4645, 1.5824])\n",
      "tensor([0.7264, 0.4645, 1.5867])\n",
      "tensor([0.7264, 0.4645, 1.5911])\n",
      "tensor([0.7264, 0.4645, 1.5954])\n",
      "tensor([0.7264, 0.4645, 1.5997])\n",
      "tensor([0.7264, 0.4645, 1.6040])\n",
      "tensor([0.7264, 0.4645, 1.6083])\n",
      "tensor([0.7264, 0.4645, 1.6127])\n",
      "tensor([0.7264, 0.4645, 1.6170])\n",
      "tensor([0.7264, 0.4645, 1.6213])\n",
      "tensor([0.7264, 0.4645, 1.6256])\n",
      "tensor([0.7264, 0.4645, 1.6300])\n",
      "tensor([0.7264, 0.4645, 1.6343])\n",
      "tensor([0.7264, 0.4645, 1.6386])\n",
      "tensor([0.7264, 0.4645, 1.6429])\n",
      "tensor([0.7264, 0.4645, 1.6472])\n",
      "tensor([0.7264, 0.4645, 1.6516])\n",
      "tensor([0.7264, 0.4645, 1.6559])\n",
      "tensor([0.7264, 0.4645, 1.6602])\n",
      "tensor([0.7264, 0.4645, 1.6645])\n",
      "tensor([0.7264, 0.4645, 1.6688])\n",
      "tensor([0.7264, 0.4645, 1.6732])\n",
      "tensor([0.7264, 0.4645, 1.6775])\n",
      "tensor([0.7264, 0.4645, 1.6818])\n",
      "tensor([0.7264, 0.4645, 1.6861])\n",
      "tensor([0.7264, 0.4645, 1.6905])\n",
      "tensor([0.7264, 0.4645, 1.6948])\n",
      "tensor([0.7264, 0.4645, 1.6991])\n",
      "tensor([0.7264, 0.4645, 1.7034])\n",
      "tensor([0.7264, 0.4645, 1.7077])\n",
      "tensor([0.7264, 0.4645, 1.7121])\n",
      "tensor([0.7264, 0.4645, 1.7164])\n",
      "tensor([0.7264, 0.4645, 1.7207])\n",
      "tensor([0.7264, 0.4645, 1.7250])\n",
      "tensor([0.7264, 0.4645, 1.7293])\n",
      "tensor([0.7264, 0.4645, 1.7337])\n",
      "tensor([0.7264, 0.4645, 1.7380])\n",
      "tensor([0.7264, 0.4645, 1.7423])\n",
      "tensor([0.7264, 0.4645, 1.7466])\n",
      "tensor([0.7264, 0.4645, 1.7510])\n",
      "tensor([0.7264, 0.4645, 1.7553])\n",
      "tensor([0.7264, 0.4645, 1.7596])\n",
      "tensor([0.7264, 0.4645, 1.7639])\n",
      "tensor([0.7264, 0.4645, 1.7682])\n",
      "tensor([0.7264, 0.4645, 1.7726])\n",
      "tensor([0.7264, 0.4645, 1.7769])\n",
      "tensor([0.7264, 0.4645, 1.7812])\n",
      "tensor([0.7264, 0.4645, 1.7855])\n",
      "tensor([0.7264, 0.4645, 1.7898])\n",
      "tensor([0.7264, 0.4645, 1.7942])\n",
      "tensor([0.7264, 0.4645, 1.7985])\n",
      "tensor([0.7264, 0.4645, 1.8028])\n",
      "tensor([0.7264, 0.4645, 1.8071])\n",
      "tensor([0.7264, 0.4645, 1.8115])\n",
      "tensor([0.7264, 0.4645, 1.8158])\n",
      "tensor([0.7264, 0.4645, 1.8201])\n",
      "tensor([0.7264, 0.4645, 1.8244])\n",
      "tensor([0.7264, 0.4645, 1.8287])\n",
      "tensor([0.7264, 0.4645, 1.8331])\n",
      "tensor([0.7264, 0.4645, 1.8374])\n",
      "tensor([0.7264, 0.4645, 1.8417])\n",
      "tensor([0.7264, 0.4645, 1.8460])\n",
      "tensor([0.7264, 0.4645, 1.8503])\n",
      "tensor([0.7264, 0.4645, 1.8547])\n",
      "tensor([0.7264, 0.4645, 1.8590])\n",
      "tensor([0.7264, 0.4645, 1.8633])\n",
      "tensor([0.7264, 0.4645, 1.8676])\n",
      "tensor([0.7264, 0.4645, 1.8720])\n",
      "tensor([0.7264, 0.4645, 1.8763])\n",
      "tensor([0.7264, 0.4645, 1.8806])\n",
      "tensor([0.7264, 0.4645, 1.8849])\n",
      "tensor([0.7264, 0.4645, 1.8892])\n",
      "tensor([0.7264, 0.4645, 1.8936])\n",
      "tensor([0.7264, 0.4645, 1.8979])\n",
      "tensor([0.7264, 0.4645, 1.9022])\n",
      "tensor([0.7264, 0.4645, 1.9065])\n",
      "tensor([0.7264, 0.4645, 1.9108])\n",
      "tensor([0.7264, 0.4645, 1.9152])\n",
      "tensor([0.7264, 0.4645, 1.9195])\n",
      "tensor([0.7264, 0.4645, 1.9238])\n",
      "tensor([0.7264, 0.4645, 1.9281])\n",
      "tensor([0.7264, 0.4645, 1.9325])\n",
      "tensor([0.7264, 0.4645, 1.9368])\n",
      "tensor([0.7264, 0.4645, 1.9411])\n",
      "tensor([0.7264, 0.4645, 1.9454])\n",
      "tensor([0.7264, 0.4645, 1.9497])\n",
      "tensor([0.7264, 0.4645, 1.9541])\n",
      "tensor([0.7264, 0.4645, 1.9584])\n",
      "tensor([0.7264, 0.4645, 1.9627])\n",
      "tensor([0.7264, 0.4645, 1.9670])\n",
      "tensor([0.7264, 0.4645, 1.9713])\n",
      "tensor([0.7264, 0.4645, 1.9757])\n",
      "tensor([0.7264, 0.4645, 1.9800])\n",
      "tensor([0.7264, 0.4645, 1.9843])\n",
      "tensor([0.7264, 0.4645, 1.9886])\n",
      "tensor([0.7264, 0.4645, 1.9929])\n",
      "tensor([0.7264, 0.4645, 1.9973])\n",
      "tensor([0.7264, 0.4645, 2.0016])\n",
      "tensor([0.7264, 0.4645, 2.0059])\n",
      "tensor([0.7264, 0.4645, 2.0102])\n",
      "tensor([0.7264, 0.4645, 2.0146])\n",
      "tensor([0.7264, 0.4645, 2.0189])\n",
      "tensor([0.7264, 0.4645, 2.0232])\n",
      "tensor([0.7264, 0.4645, 2.0275])\n",
      "tensor([0.7264, 0.4645, 2.0318])\n",
      "tensor([0.7264, 0.4645, 2.0362])\n",
      "tensor([0.7264, 0.4645, 2.0405])\n",
      "tensor([0.7264, 0.4645, 2.0448])\n",
      "tensor([0.7264, 0.4645, 2.0491])\n",
      "tensor([0.7264, 0.4645, 2.0534])\n",
      "tensor([0.7264, 0.4645, 2.0578])\n",
      "tensor([0.7264, 0.4645, 2.0621])\n",
      "tensor([0.7264, 0.4645, 2.0664])\n",
      "tensor([0.7264, 0.4645, 2.0707])\n",
      "tensor([0.7264, 0.4645, 2.0751])\n",
      "tensor([0.7264, 0.4645, 2.0794])\n",
      "tensor([0.7264, 0.4645, 2.0837])\n",
      "tensor([0.7264, 0.4645, 2.0880])\n",
      "tensor([0.7264, 0.4645, 2.0923])\n",
      "tensor([0.7264, 0.4645, 2.0967])\n",
      "tensor([0.7264, 0.4645, 2.1010])\n",
      "tensor([0.7264, 0.4645, 2.1053])\n",
      "tensor([0.7264, 0.4645, 2.1096])\n",
      "tensor([0.7264, 0.4645, 2.1139])\n",
      "tensor([0.7264, 0.4645, 2.1183])\n",
      "tensor([0.7264, 0.4645, 2.1226])\n",
      "tensor([0.7264, 0.4645, 2.1269])\n",
      "tensor([0.7264, 0.4645, 2.1312])\n",
      "tensor([0.7264, 0.4645, 2.1356])\n",
      "tensor([0.7264, 0.4645, 2.1399])\n",
      "tensor([0.7264, 0.4645, 2.1442])\n",
      "tensor([0.7264, 0.4645, 2.1485])\n",
      "tensor([0.7264, 0.4645, 2.1528])\n",
      "tensor([0.7264, 0.4645, 2.1572])\n",
      "tensor([0.7264, 0.4645, 2.1615])\n",
      "tensor([0.7264, 0.4645, 2.1658])\n",
      "tensor([0.7264, 0.4645, 2.1701])\n",
      "tensor([0.7264, 0.4645, 2.1744])\n",
      "tensor([0.7264, 0.4645, 2.1788])\n",
      "tensor([0.7264, 0.4645, 2.1831])\n",
      "tensor([0.7264, 0.4645, 2.1874])\n",
      "tensor([0.7264, 0.4645, 2.1917])\n",
      "tensor([0.7264, 0.4645, 2.1961])\n",
      "tensor([0.7264, 0.4645, 2.2004])\n",
      "tensor([0.7264, 0.4645, 2.2047])\n",
      "tensor([0.7264, 0.4645, 2.2090])\n",
      "tensor([0.7264, 0.4645, 2.2133])\n",
      "tensor([0.7264, 0.4645, 2.2177])\n",
      "tensor([0.7264, 0.4645, 2.2220])\n",
      "tensor([0.7264, 0.4645, 2.2263])\n",
      "tensor([0.7264, 0.4645, 2.2306])\n",
      "tensor([0.7264, 0.4645, 2.2349])\n",
      "tensor([0.7264, 0.4645, 2.2393])\n",
      "tensor([0.7264, 0.4645, 2.2436])\n",
      "tensor([0.7264, 0.4645, 2.2479])\n",
      "tensor([0.7264, 0.4645, 2.2522])\n",
      "tensor([0.7264, 0.4645, 2.2566])\n",
      "tensor([0.7264, 0.4645, 2.2609])\n",
      "tensor([0.7264, 0.4645, 2.2652])\n",
      "tensor([0.7264, 0.4645, 2.2695])\n",
      "tensor([0.7264, 0.4645, 2.2738])\n",
      "tensor([0.7264, 0.4645, 2.2782])\n",
      "tensor([0.7264, 0.4645, 2.2825])\n",
      "tensor([0.7264, 0.4645, 2.2868])\n",
      "tensor([0.7264, 0.4645, 2.2911])\n",
      "tensor([0.7264, 0.4645, 2.2954])\n",
      "tensor([0.7264, 0.4645, 2.2998])\n",
      "tensor([0.7264, 0.4645, 2.3041])\n",
      "tensor([0.7264, 0.4645, 2.3084])\n",
      "tensor([0.7264, 0.4645, 2.3127])\n",
      "tensor([0.7264, 0.4645, 2.3171])\n",
      "tensor([0.7264, 0.4645, 2.3214])\n",
      "tensor([0.7264, 0.4645, 2.3257])\n",
      "tensor([0.7264, 0.4645, 2.3300])\n",
      "tensor([0.7264, 0.4645, 2.3343])\n",
      "tensor([0.7264, 0.4645, 2.3387])\n",
      "tensor([0.7264, 0.4645, 2.3430])\n",
      "tensor([0.7264, 0.4645, 2.3473])\n",
      "tensor([0.7264, 0.4645, 2.3516])\n",
      "tensor([0.7264, 0.4645, 2.3559])\n",
      "tensor([0.7264, 0.4645, 2.3603])\n",
      "tensor([0.7264, 0.4645, 2.3646])\n",
      "tensor([0.7264, 0.4645, 2.3689])\n",
      "tensor([0.7264, 0.4645, 2.3732])\n",
      "tensor([0.7264, 0.4645, 2.3776])\n",
      "tensor([0.7264, 0.4645, 2.3819])\n",
      "tensor([0.7264, 0.4645, 2.3862])\n",
      "tensor([0.7264, 0.4645, 2.3905])\n",
      "tensor([0.7264, 0.4645, 2.3948])\n",
      "tensor([0.7264, 0.4645, 2.3992])\n",
      "tensor([0.7264, 0.4645, 2.4035])\n",
      "tensor([0.7264, 0.4645, 2.4078])\n",
      "tensor([0.7264, 0.4645, 2.4121])\n",
      "tensor([0.7264, 0.4645, 2.4164])\n",
      "tensor([0.7264, 0.4645, 2.4208])\n",
      "tensor([0.7264, 0.4645, 2.4251])\n",
      "tensor([0.7264, 0.4645, 2.4294])\n",
      "tensor([0.7264, 0.4645, 2.4337])\n",
      "tensor([0.7264, 0.4645, 2.4381])\n",
      "tensor([0.7264, 0.4645, 2.4424])\n",
      "tensor([0.7264, 0.4645, 2.4467])\n",
      "tensor([0.7264, 0.4645, 2.4510])\n",
      "tensor([0.7264, 0.4645, 2.4553])\n",
      "tensor([0.7264, 0.4645, 2.4597])\n",
      "tensor([0.7264, 0.4645, 2.4640])\n",
      "tensor([0.7264, 0.4645, 2.4683])\n",
      "tensor([0.7264, 0.4645, 2.4726])\n",
      "tensor([0.7264, 0.4645, 2.4769])\n",
      "tensor([0.7264, 0.4645, 2.4813])\n",
      "tensor([0.7264, 0.4645, 2.4856])\n",
      "tensor([0.7264, 0.4645, 2.4899])\n",
      "tensor([0.7264, 0.4645, 2.4942])\n",
      "tensor([0.7264, 0.4645, 2.4986])\n",
      "tensor([0.7264, 0.4645, 2.5029])\n",
      "tensor([0.7264, 0.4645, 2.5072])\n",
      "tensor([0.7264, 0.4645, 2.5115])\n",
      "tensor([0.7264, 0.4645, 2.5158])\n",
      "tensor([0.7264, 0.4645, 2.5202])\n",
      "tensor([0.7264, 0.4645, 2.5245])\n",
      "tensor([0.7264, 0.4645, 2.5288])\n",
      "tensor([0.7264, 0.4645, 2.5331])\n",
      "tensor([0.7264, 0.4645, 2.5374])\n",
      "tensor([0.7264, 0.4645, 2.5418])\n",
      "tensor([0.7264, 0.4645, 2.5461])\n",
      "tensor([0.7264, 0.4645, 2.5504])\n",
      "tensor([0.7264, 0.4645, 2.5547])\n",
      "tensor([0.7264, 0.4645, 2.5590])\n",
      "tensor([0.7264, 0.4645, 2.5634])\n",
      "tensor([0.7264, 0.4645, 2.5677])\n",
      "tensor([0.7264, 0.4645, 2.5720])\n",
      "tensor([0.7264, 0.4645, 2.5763])\n",
      "tensor([0.7264, 0.4645, 2.5807])\n",
      "tensor([0.7264, 0.4645, 2.5850])\n",
      "tensor([0.7264, 0.4645, 2.5893])\n",
      "tensor([0.7264, 0.4645, 2.5936])\n",
      "tensor([0.7264, 0.4645, 2.5979])\n",
      "tensor([0.7264, 0.4645, 2.6023])\n",
      "tensor([0.7264, 0.4645, 2.6066])\n",
      "tensor([0.7264, 0.4645, 2.6109])\n",
      "tensor([0.7264, 0.4645, 2.6152])\n",
      "tensor([0.7264, 0.4645, 2.6195])\n",
      "tensor([0.7264, 0.4645, 2.6239])\n",
      "tensor([0.7264, 0.4645, 2.6282])\n",
      "tensor([0.7264, 0.4645, 2.6325])\n",
      "tensor([0.7264, 0.4645, 2.6368])\n",
      "tensor([0.7264, 0.4645, 2.6412])\n",
      "tensor([0.7264, 0.4645, 2.6455])\n",
      "tensor([0.7264, 0.4645, 2.6498])\n",
      "tensor([0.7264, 0.4645, 2.6541])\n",
      "tensor([0.7264, 0.4645, 2.6584])\n",
      "tensor([0.7264, 0.4645, 2.6628])\n",
      "tensor([0.7264, 0.4645, 2.6671])\n",
      "tensor([0.7264, 0.4645, 2.6714])\n",
      "tensor([0.7264, 0.4645, 2.6757])\n",
      "tensor([0.7264, 0.4645, 2.6800])\n",
      "tensor([0.7264, 0.4645, 2.6844])\n",
      "tensor([0.7264, 0.4645, 2.6887])\n",
      "tensor([0.7264, 0.4645, 2.6930])\n",
      "tensor([0.7264, 0.4645, 2.6973])\n",
      "tensor([0.7264, 0.4645, 2.7017])\n",
      "tensor([0.7264, 0.4645, 2.7060])\n",
      "tensor([0.7264, 0.4645, 2.7103])\n",
      "tensor([0.7264, 0.4645, 2.7146])\n",
      "tensor([0.7264, 0.4645, 2.7189])\n",
      "tensor([0.7264, 0.4645, 2.7233])\n",
      "tensor([0.7264, 0.4645, 2.7276])\n",
      "tensor([0.7264, 0.4645, 2.7319])\n",
      "tensor([0.7264, 0.4645, 2.7362])\n",
      "tensor([0.7264, 0.4645, 2.7405])\n",
      "tensor([0.7264, 0.4645, 2.7449])\n",
      "tensor([0.7264, 0.4645, 2.7492])\n",
      "tensor([0.7264, 0.4645, 2.7535])\n",
      "tensor([0.7264, 0.4645, 2.7578])\n",
      "tensor([0.7264, 0.4645, 2.7622])\n",
      "tensor([0.7264, 0.4645, 2.7665])\n",
      "tensor([0.7264, 0.4645, 2.7708])\n",
      "tensor([0.7264, 0.4645, 2.7751])\n",
      "tensor([0.7264, 0.4645, 2.7794])\n",
      "tensor([0.7264, 0.4645, 2.7838])\n",
      "tensor([0.7264, 0.4645, 2.7881])\n",
      "tensor([0.7264, 0.4645, 2.7924])\n",
      "tensor([0.7264, 0.4645, 2.7967])\n",
      "tensor([0.7264, 0.4645, 2.8010])\n",
      "tensor([0.7264, 0.4645, 2.8054])\n",
      "tensor([0.7264, 0.4645, 2.8097])\n",
      "tensor([0.7264, 0.4645, 2.8140])\n",
      "tensor([0.7264, 0.4645, 2.8183])\n",
      "tensor([0.7264, 0.4645, 2.8227])\n",
      "tensor([0.7264, 0.4645, 2.8270])\n",
      "tensor([0.7264, 0.4645, 2.8313])\n",
      "tensor([0.7264, 0.4645, 2.8356])\n",
      "tensor([0.7264, 0.4645, 2.8399])\n",
      "tensor([0.7264, 0.4645, 2.8443])\n",
      "tensor([0.7264, 0.4645, 2.8486])\n",
      "tensor([0.7264, 0.4645, 2.8529])\n",
      "tensor([0.7264, 0.4645, 2.8572])\n",
      "tensor([0.7264, 0.4645, 2.8615])\n",
      "tensor([0.7264, 0.4645, 2.8659])\n",
      "tensor([0.7264, 0.4645, 2.8702])\n",
      "tensor([0.7264, 0.4645, 2.8745])\n",
      "tensor([0.7264, 0.4645, 2.8788])\n",
      "tensor([0.7264, 0.4645, 2.8832])\n",
      "tensor([0.7264, 0.4645, 2.8875])\n",
      "tensor([0.7264, 0.4645, 2.8918])\n",
      "tensor([0.7264, 0.4645, 2.8961])\n",
      "tensor([0.7264, 0.4645, 2.9004])\n",
      "tensor([0.7264, 0.4645, 2.9048])\n",
      "tensor([0.7264, 0.4645, 2.9091])\n",
      "tensor([0.7264, 0.4645, 2.9134])\n",
      "tensor([0.7264, 0.4645, 2.9177])\n",
      "tensor([0.7264, 0.4645, 2.9220])\n",
      "tensor([0.7264, 0.4645, 2.9264])\n",
      "tensor([0.7264, 0.4645, 2.9307])\n",
      "tensor([0.7264, 0.4645, 2.9350])\n",
      "tensor([0.7264, 0.4645, 2.9393])\n",
      "tensor([0.7264, 0.4645, 2.9437])\n",
      "tensor([0.7264, 0.4645, 2.9480])\n",
      "tensor([0.7264, 0.4645, 2.9523])\n",
      "tensor([0.7264, 0.4645, 2.9566])\n",
      "tensor([0.7264, 0.4645, 2.9609])\n",
      "tensor([0.7264, 0.4645, 2.9653])\n",
      "tensor([0.7264, 0.4645, 2.9696])\n",
      "tensor([0.7264, 0.4645, 2.9739])\n",
      "tensor([0.7264, 0.4645, 2.9782])\n",
      "tensor([0.7264, 0.4645, 2.9825])\n",
      "tensor([0.7264, 0.4645, 2.9869])\n",
      "tensor([0.7264, 0.4645, 2.9912])\n",
      "tensor([0.7264, 0.4645, 2.9955])\n",
      "tensor([0.7264, 0.4645, 2.9998])\n",
      "tensor([0.7264, 0.4645, 3.0042])\n",
      "tensor([0.7264, 0.4645, 3.0085])\n",
      "tensor([0.7264, 0.4645, 3.0128])\n",
      "tensor([0.7264, 0.4645, 3.0171])\n",
      "tensor([0.7264, 0.4645, 3.0214])\n",
      "tensor([0.7264, 0.4645, 3.0258])\n",
      "tensor([0.7264, 0.4645, 3.0301])\n",
      "tensor([0.7264, 0.4645, 3.0344])\n",
      "tensor([0.7264, 0.4645, 3.0387])\n",
      "tensor([0.7264, 0.4645, 3.0430])\n",
      "tensor([0.7264, 0.4645, 3.0474])\n",
      "tensor([0.7264, 0.4645, 3.0517])\n",
      "tensor([0.7264, 0.4645, 3.0560])\n",
      "tensor([0.7264, 0.4645, 3.0603])\n",
      "tensor([0.7264, 0.4645, 3.0647])\n",
      "tensor([0.7264, 0.4645, 3.0690])\n",
      "tensor([0.7264, 0.4645, 3.0733])\n",
      "tensor([0.7264, 0.4645, 3.0776])\n",
      "tensor([0.7264, 0.4645, 3.0819])\n",
      "tensor([0.7264, 0.4645, 3.0863])\n",
      "tensor([0.7264, 0.4645, 3.0906])\n",
      "tensor([0.7264, 0.4645, 3.0949])\n",
      "tensor([0.7264, 0.4645, 3.0992])\n",
      "tensor([0.7264, 0.4645, 3.1035])\n",
      "tensor([0.7264, 0.4645, 3.1079])\n",
      "tensor([0.7264, 0.4645, 3.1122])\n",
      "tensor([0.7264, 0.4645, 3.1165])\n",
      "tensor([0.7264, 0.4645, 3.1208])\n",
      "tensor([0.7264, 0.4645, 3.1251])\n",
      "tensor([0.7264, 0.4645, 3.1295])\n",
      "tensor([0.7264, 0.4645, 3.1338])\n",
      "tensor([0.7264, 0.4645, 3.1381])\n",
      "tensor([0.7264, 0.4645, 3.1424])\n",
      "tensor([0.7264, 0.4645, 3.1468])\n",
      "tensor([0.7264, 0.4645, 3.1511])\n",
      "tensor([0.7264, 0.4645, 3.1554])\n",
      "tensor([0.7264, 0.4645, 3.1597])\n",
      "tensor([0.7264, 0.4645, 3.1640])\n",
      "tensor([0.7264, 0.4645, 3.1684])\n",
      "tensor([0.7264, 0.4645, 3.1727])\n",
      "tensor([0.7264, 0.4645, 3.1770])\n",
      "tensor([0.7264, 0.4645, 3.1813])\n",
      "tensor([0.7264, 0.4645, 3.1856])\n",
      "tensor([0.7264, 0.4645, 3.1900])\n",
      "tensor([0.7264, 0.4645, 3.1943])\n",
      "tensor([0.7264, 0.4645, 3.1986])\n",
      "tensor([0.7264, 0.4645, 3.2029])\n",
      "tensor([0.7264, 0.4645, 3.2073])\n",
      "tensor([0.7264, 0.4645, 3.2116])\n",
      "tensor([0.7264, 0.4645, 3.2159])\n",
      "tensor([0.7264, 0.4645, 3.2202])\n",
      "tensor([0.7264, 0.4645, 3.2245])\n",
      "tensor([0.7264, 0.4645, 3.2289])\n",
      "tensor([0.7264, 0.4645, 3.2332])\n",
      "tensor([0.7264, 0.4645, 3.2375])\n",
      "tensor([0.7264, 0.4645, 3.2418])\n",
      "tensor([0.7264, 0.4645, 3.2461])\n",
      "tensor([0.7264, 0.4645, 3.2505])\n",
      "tensor([0.7264, 0.4645, 3.2548])\n",
      "tensor([0.7264, 0.4645, 3.2591])\n",
      "tensor([0.7264, 0.4645, 3.2634])\n",
      "tensor([0.7264, 0.4645, 3.2678])\n",
      "tensor([0.7264, 0.4645, 3.2721])\n",
      "tensor([0.7264, 0.4645, 3.2764])\n",
      "tensor([0.7264, 0.4645, 3.2807])\n",
      "tensor([0.7264, 0.4645, 3.2850])\n",
      "tensor([0.7264, 0.4645, 3.2894])\n",
      "tensor([0.7264, 0.4645, 3.2937])\n",
      "tensor([0.7264, 0.4645, 3.2980])\n",
      "tensor([0.7264, 0.4645, 3.3023])\n",
      "tensor([0.7264, 0.4645, 3.3066])\n",
      "tensor([0.7264, 0.4645, 3.3110])\n",
      "tensor([0.7264, 0.4645, 3.3153])\n",
      "tensor([0.7264, 0.4645, 3.3196])\n",
      "tensor([0.7264, 0.4645, 3.3239])\n",
      "tensor([0.7264, 0.4645, 3.3283])\n",
      "tensor([0.7264, 0.4645, 3.3326])\n",
      "tensor([0.7264, 0.4645, 3.3369])\n",
      "tensor([0.7264, 0.4645, 3.3412])\n",
      "tensor([0.7264, 0.4645, 3.3455])\n",
      "tensor([0.7264, 0.4645, 3.3499])\n",
      "tensor([0.7264, 0.4645, 3.3542])\n",
      "tensor([0.7264, 0.4645, 3.3585])\n",
      "tensor([0.7264, 0.4645, 3.3628])\n",
      "tensor([0.7264, 0.4645, 3.3671])\n",
      "tensor([0.7264, 0.4645, 3.3715])\n",
      "tensor([0.7264, 0.4645, 3.3758])\n",
      "tensor([0.7264, 0.4645, 3.3801])\n",
      "tensor([0.7264, 0.4645, 3.3844])\n",
      "tensor([0.7264, 0.4645, 3.3888])\n",
      "tensor([0.7264, 0.4645, 3.3931])\n",
      "tensor([0.7264, 0.4645, 3.3974])\n",
      "tensor([0.7264, 0.4645, 3.4017])\n",
      "tensor([0.7264, 0.4645, 3.4060])\n",
      "tensor([0.7264, 0.4645, 3.4104])\n",
      "tensor([0.7264, 0.4645, 3.4147])\n",
      "tensor([0.7264, 0.4645, 3.4190])\n",
      "tensor([0.7264, 0.4645, 3.4233])\n",
      "tensor([0.7264, 0.4645, 3.4276])\n",
      "tensor([0.7264, 0.4645, 3.4320])\n",
      "tensor([0.7264, 0.4645, 3.4363])\n",
      "tensor([0.7264, 0.4645, 3.4406])\n",
      "tensor([0.7264, 0.4645, 3.4449])\n",
      "tensor([0.7264, 0.4645, 3.4493])\n",
      "tensor([0.7264, 0.4645, 3.4536])\n",
      "tensor([0.7264, 0.4645, 3.4579])\n",
      "tensor([0.7264, 0.4645, 3.4622])\n",
      "tensor([0.7264, 0.4645, 3.4665])\n",
      "tensor([0.7264, 0.4645, 3.4709])\n",
      "tensor([0.7264, 0.4645, 3.4752])\n",
      "tensor([0.7264, 0.4645, 3.4795])\n",
      "tensor([0.7264, 0.4645, 3.4838])\n",
      "tensor([0.7264, 0.4645, 3.4881])\n",
      "tensor([0.7264, 0.4645, 3.4925])\n",
      "tensor([0.7264, 0.4645, 3.4968])\n",
      "tensor([0.7264, 0.4645, 3.5011])\n",
      "tensor([0.7264, 0.4645, 3.5054])\n",
      "tensor([0.7264, 0.4645, 3.5098])\n",
      "tensor([0.7264, 0.4645, 3.5141])\n",
      "tensor([0.7264, 0.4645, 3.5184])\n",
      "tensor([0.7264, 0.4645, 3.5227])\n",
      "tensor([0.7264, 0.4645, 3.5270])\n",
      "tensor([0.7264, 0.4645, 3.5314])\n",
      "tensor([0.7264, 0.4645, 3.5357])\n",
      "tensor([0.7264, 0.4645, 3.5400])\n",
      "tensor([0.7264, 0.4645, 3.5443])\n",
      "tensor([0.7264, 0.4645, 3.5486])\n",
      "tensor([0.7264, 0.4645, 3.5530])\n",
      "tensor([0.7264, 0.4645, 3.5573])\n",
      "tensor([0.7264, 0.4645, 3.5616])\n",
      "tensor([0.7264, 0.4645, 3.5659])\n",
      "tensor([0.7264, 0.4645, 3.5703])\n",
      "tensor([0.7264, 0.4645, 3.5746])\n",
      "tensor([0.7264, 0.4645, 3.5789])\n",
      "tensor([0.7264, 0.4645, 3.5832])\n",
      "tensor([0.7264, 0.4645, 3.5875])\n",
      "tensor([0.7264, 0.4645, 3.5919])\n",
      "tensor([0.7264, 0.4645, 3.5962])\n",
      "tensor([0.7264, 0.4645, 3.6005])\n",
      "tensor([0.7264, 0.4645, 3.6048])\n",
      "tensor([0.7264, 0.4645, 3.6091])\n",
      "tensor([0.7264, 0.4645, 3.6135])\n",
      "tensor([0.7264, 0.4645, 3.6178])\n",
      "tensor([0.7264, 0.4645, 3.6221])\n",
      "tensor([0.7264, 0.4645, 3.6264])\n",
      "tensor([0.7264, 0.4645, 3.6308])\n",
      "tensor([0.7264, 0.4645, 3.6351])\n",
      "tensor([0.7264, 0.4645, 3.6394])\n",
      "tensor([0.7264, 0.4645, 3.6437])\n",
      "tensor([0.7264, 0.4645, 3.6480])\n",
      "tensor([0.7264, 0.4645, 3.6524])\n",
      "tensor([0.7264, 0.4645, 3.6567])\n",
      "tensor([0.7264, 0.4645, 3.6610])\n",
      "tensor([0.7264, 0.4645, 3.6653])\n",
      "tensor([0.7264, 0.4645, 3.6696])\n",
      "tensor([0.7264, 0.4645, 3.6740])\n",
      "tensor([0.7264, 0.4645, 3.6783])\n",
      "tensor([0.7264, 0.4645, 3.6826])\n",
      "tensor([0.7264, 0.4645, 3.6869])\n",
      "tensor([0.7264, 0.4645, 3.6912])\n",
      "tensor([0.7264, 0.4645, 3.6956])\n",
      "tensor([0.7264, 0.4645, 3.6999])\n",
      "tensor([0.7264, 0.4645, 3.7042])\n",
      "tensor([0.7264, 0.4645, 3.7085])\n",
      "tensor([0.7264, 0.4645, 3.7129])\n",
      "tensor([0.7264, 0.4645, 3.7172])\n",
      "tensor([0.7264, 0.4645, 3.7215])\n",
      "tensor([0.7264, 0.4645, 3.7258])\n",
      "tensor([0.7264, 0.4645, 3.7301])\n",
      "tensor([0.7264, 0.4645, 3.7345])\n",
      "tensor([0.7264, 0.4645, 3.7388])\n",
      "tensor([0.7264, 0.4645, 3.7431])\n",
      "tensor([0.7264, 0.4645, 3.7474])\n",
      "tensor([0.7264, 0.4645, 3.7517])\n",
      "tensor([0.7264, 0.4645, 3.7561])\n",
      "tensor([0.7264, 0.4645, 3.7604])\n",
      "tensor([0.7264, 0.4645, 3.7647])\n",
      "tensor([0.7264, 0.4645, 3.7690])\n",
      "tensor([0.7264, 0.4645, 3.7734])\n",
      "tensor([0.7264, 0.4645, 3.7777])\n",
      "tensor([0.7264, 0.4645, 3.7820])\n",
      "tensor([0.7264, 0.4645, 3.7863])\n",
      "tensor([0.7264, 0.4645, 3.7906])\n",
      "tensor([0.7264, 0.4645, 3.7950])\n",
      "tensor([0.7264, 0.4645, 3.7993])\n",
      "tensor([0.7264, 0.4645, 3.8036])\n",
      "tensor([0.7264, 0.4645, 3.8079])\n",
      "tensor([0.7264, 0.4645, 3.8122])\n",
      "tensor([0.7264, 0.4645, 3.8166])\n",
      "tensor([0.7264, 0.4645, 3.8209])\n",
      "tensor([0.7264, 0.4645, 3.8252])\n",
      "tensor([0.7264, 0.4645, 3.8295])\n",
      "tensor([0.7264, 0.4645, 3.8339])\n",
      "tensor([0.7264, 0.4645, 3.8382])\n",
      "tensor([0.7264, 0.4645, 3.8425])\n",
      "tensor([0.7264, 0.4645, 3.8468])\n",
      "tensor([0.7264, 0.4645, 3.8511])\n",
      "tensor([0.7264, 0.4645, 3.8555])\n",
      "tensor([0.7264, 0.4645, 3.8598])\n",
      "tensor([0.7264, 0.4645, 3.8641])\n",
      "tensor([0.7264, 0.4645, 3.8684])\n",
      "tensor([0.7264, 0.4645, 3.8727])\n",
      "tensor([0.7264, 0.4645, 3.8771])\n",
      "tensor([0.7264, 0.4645, 3.8814])\n",
      "tensor([0.7264, 0.4645, 3.8857])\n",
      "tensor([0.7264, 0.4645, 3.8900])\n",
      "tensor([0.7264, 0.4645, 3.8944])\n",
      "tensor([0.7264, 0.4645, 3.8987])\n",
      "tensor([0.7264, 0.4645, 3.9030])\n",
      "tensor([0.7264, 0.4645, 3.9073])\n",
      "tensor([0.7264, 0.4645, 3.9116])\n",
      "tensor([0.7264, 0.4645, 3.9160])\n",
      "tensor([0.7264, 0.4645, 3.9203])\n",
      "tensor([0.7264, 0.4645, 3.9246])\n",
      "tensor([0.7264, 0.4645, 3.9289])\n",
      "tensor([0.7264, 0.4645, 3.9332])\n",
      "tensor([0.7264, 0.4645, 3.9376])\n",
      "tensor([0.7264, 0.4645, 3.9419])\n",
      "tensor([0.7264, 0.4645, 3.9462])\n",
      "tensor([0.7264, 0.4645, 3.9505])\n",
      "tensor([0.7264, 0.4645, 3.9549])\n",
      "tensor([0.7264, 0.4645, 3.9592])\n",
      "tensor([0.7264, 0.4645, 3.9635])\n",
      "tensor([0.7264, 0.4645, 3.9678])\n",
      "tensor([0.7264, 0.4645, 3.9721])\n",
      "tensor([0.7264, 0.4645, 3.9765])\n",
      "tensor([0.7264, 0.4645, 3.9808])\n",
      "tensor([0.7264, 0.4645, 3.9851])\n",
      "tensor([0.7264, 0.4645, 3.9894])\n",
      "tensor([0.7264, 0.4645, 3.9937])\n",
      "tensor([0.7264, 0.4645, 3.9981])\n",
      "tensor([0.7264, 0.4645, 4.0024])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "io_scale = lse_data['io_scale']\n",
    "b_min = 0.01\n",
    "b_max = 10000\n",
    "b_grow = 1.01\n",
    "b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "drone_id = 1\n",
    "FreeEnergy = []\n",
    "betas = []\n",
    "\n",
    "s = time.time()\n",
    "with torch.no_grad():\n",
    "    # forward pass: no activations are saved for grad\n",
    "    _, actions = vrp_net(data, mod='eval_greedy')\n",
    "e = time.time()\n",
    "actions.detach()\n",
    "d_mins = utils.route_cost(data, actions)[drone_id:drone_id+1]\n",
    "d_array_est = (d_mins - 1.0) * torch.rand(1,int(n_drone_routes[drone_id,0])) + 1.0\n",
    "Fmin_est = logSumExp(d_array_est, b_min)\n",
    "print(Fmin_est)\n",
    "# beta=b_min\n",
    "for beta in b_array:\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    In = torch.tensor([\n",
    "        Fmin_est.to(device),\n",
    "        io_scale*d_mins,\n",
    "        torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device)\n",
    "    ])\n",
    "    # update annealing parameter\n",
    "    print(In)\n",
    "    # print(In[2].detach().numpy())\n",
    "    betas.append(In[2].detach().numpy())\n",
    "    # print(betas)\n",
    "    Out = lse_net(In)/io_scale - 0*(1/beta * torch.log(n_drone_routes[drone_id,0])).to(device)\n",
    "    # print(beta, torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])), In, Out)\n",
    "    # print(In)\n",
    "    FreeEnergy.append(Out[0].detach().numpy())\n",
    "\n",
    "    # beta = beta * b_grow\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(6,2))\n",
    "plt.plot(betas, FreeEnergy)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute an estimate of free energy at b_min for all drones using d_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:1.000e-04\n",
      "\tEpoch: 0\tVRP_runtime: 0.03s\tFreeEnergy: 1.27\tF_Grad: 9.160e-01\td_min_mean: 0.52\n",
      "\tEpoch: 50\tVRP_runtime: 0.01s\tFreeEnergy: 1.12\tF_Grad: 7.841e-01\td_min_mean: 0.42\n",
      "\tEpoch: 100\tVRP_runtime: 0.02s\tFreeEnergy: 1.02\tF_Grad: 6.493e-01\td_min_mean: 0.35\n",
      "\tEpoch: 150\tVRP_runtime: 0.02s\tFreeEnergy: 0.94\tF_Grad: 5.481e-01\td_min_mean: 0.30\n",
      "\tEpoch: 200\tVRP_runtime: 0.03s\tFreeEnergy: 0.89\tF_Grad: 4.486e-01\td_min_mean: 0.27\n",
      "\tEpoch: 250\tVRP_runtime: 0.02s\tFreeEnergy: 0.85\tF_Grad: 3.595e-01\td_min_mean: 0.24\n",
      "\tEpoch: 300\tVRP_runtime: 0.02s\tFreeEnergy: 0.82\tF_Grad: 2.787e-01\td_min_mean: 0.22\n",
      "\tEpoch: 350\tVRP_runtime: 0.02s\tFreeEnergy: 0.81\tF_Grad: 2.133e-01\td_min_mean: 0.21\n",
      "\tEpoch: 399\tVRP_runtime: 0.02s\tFreeEnergy: 0.79\tF_Grad: 1.596e-01\td_min_mean: 0.21\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400;\n",
    "optimizer = optim.Adam([F_base], lr=1e-3)\n",
    "# b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "io_scale = lse_data['io_scale']\n",
    "b_min = 1e-4\n",
    "b_max = 1e-4\n",
    "b_grow = 2\n",
    "b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# beta=b_min\n",
    "for beta in b_array:\n",
    "    print(f\"beta:{beta:.3e}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        s = time.time()\n",
    "        with torch.no_grad():\n",
    "            # forward pass: no activations are saved for grad\n",
    "            _, actions = vrp_net(data, mod='eval_greedy')\n",
    "        e = time.time()\n",
    "        actions.detach()\n",
    "        d_mins = utils.route_cost(data, actions)\n",
    "        # print('here0')\n",
    "        with torch.no_grad():\n",
    "            D_bmin_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "            # print('here1')\n",
    "            Fmin_tensor = logSumExp(D_bmin_tensor, beta=b_min).to(device)\n",
    "        # print('here2')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        In = torch.cat((\n",
    "            Fmin_tensor,\n",
    "            io_scale*d_mins.view(-1,1), \n",
    "            torch.ones((num_drones,1)).to(device)*torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device).to(device)), axis=1) #, torch.ones((num_drones,1)).to(device)*b_min.to(device)),axis=1)\n",
    "        # print(In)\n",
    "        Out = lse_net(In)/io_scale + d_mins.view(-1,1) #- (1/beta * torch.log(n_drone_routes)).to(device) \n",
    "        FreeEnergy = torch.mean(Out)\n",
    "        \n",
    "        # print(torch.norm(data))\n",
    "        optimizer.zero_grad()\n",
    "        FreeEnergy.backward()\n",
    "        optimizer.step()\n",
    "        # perturb and update facility location data for each drone\n",
    "        std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "        with torch.no_grad():\n",
    "            F_base += torch.normal(mean=torch.zeros(1,num_facilities,dim_), std=0.0001*torch.ones(1,num_facilities,dim_)).to(device)\n",
    "        # print(F_base)\n",
    "        F_locs = F_base.expand(num_drones, -1, -1)\n",
    "        # print(F_locs)\n",
    "        data = torch.cat((START_locs, F_locs, END_locs), dim=1)\n",
    "        if epoch % 50 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"\\tEpoch: {epoch}\\tVRP_runtime: {e-s:.2f}s\\tFreeEnergy: {FreeEnergy:.2f}\\tF_Grad: {torch.max(torch.abs(F_base.grad)):.3e}\\td_min_mean: {torch.mean(d_mins):.2f}\")\n",
    "    # update annealing parameter\n",
    "    beta = beta * b_grow\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x31866a160>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_locs = START_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(start_locs[:,0],start_locs[:,1],color='cyan',marker='.')\n",
    "end_locs = END_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(end_locs[:,0],end_locs[:,1],color='red',marker='.')\n",
    "f_locs = F_base.squeeze(0).detach().cpu().numpy()\n",
    "plt.scatter(f_locs[:,0],f_locs[:,1],color='black',marker='^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this block shoud be dF/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate $\\frac{\\partial F}{\\partial d_{min}}$ (code in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/ndxykdmj1q9cwr2kpvkvcbs80000gn/T/ipykernel_89473/1274708057.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  d_mins_torch.grad\n"
     ]
    }
   ],
   "source": [
    "# fix beta\n",
    "b = np.random.choice(b_arr)\n",
    "d_mins_torch = torch.tensor(d_mins, dtype=torch.float32, requires_grad=True).view(-1,1)\n",
    "const_bmin = -io_scale/b_arr[0] * np.log(len_Darray) * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "const_b = b * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "In = torch.concatenate((const_bmin, d_mins_torch, const_b), axis=1)\n",
    "Out = lse_net(In)\n",
    "# print(Out)\n",
    "Out[0].retain_grad()\n",
    "Out[0].backward()\n",
    "d_mins_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CLF to determin Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GD code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the Beta Loop for Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False, False,  True, False, False, False, False])\n",
      "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Filtered: tensor([ 0,  5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(20)  # Just an example tensor: [0, 1, 2, ..., 19]\n",
    "\n",
    "# Create a mask to skip every 5th element\n",
    "mask = torch.zeros(len(x), dtype=bool)\n",
    "mask[0::5] = True  # Set every 5th element to False\n",
    "print(mask)\n",
    "result = x[mask]\n",
    "\n",
    "print(\"Original:\", x)\n",
    "print(\"Filtered:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
