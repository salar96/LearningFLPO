{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning FLPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we will implement the hierarchical ML architecture to predict the parameters in the FLPO setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from VRP_Net_L import VRPNet_L\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import LSE_net\n",
    "from torch import optim\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2601, 0.2383])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.tensor([0.3,0.3]), std=torch.tensor([0.1,0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n",
      "Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed=42;\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Running on: \" , device)\n",
    "num_drones = 100 # number of FLPO instances\n",
    "num_facilities = 5\n",
    "dim_ = 2\n",
    "# START and END locations: no grads needed\n",
    "nd_per_cluster = int(num_drones/2)\n",
    "means1 = torch.tensor([[0.4,0.7]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "means2 = torch.tensor([[0.7,0.3]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std2 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "START_locs1 = torch.normal(mean=means1, std=std1)\n",
    "START_locs2 = torch.normal(mean=means2, std=std2)\n",
    "START_locs = torch.cat((START_locs1, START_locs2), axis=0)\n",
    "END_locs   = torch.ones((num_drones, 1, dim_), requires_grad=False, device=device)#torch.rand(num_drones, 1, dim_, requires_grad=False, device=device)\n",
    "\n",
    "# Facility locations: we want grads here\n",
    "# We create a base tensor with requires_grad=True, then expand it\n",
    "# F_base = torch.rand(1, num_facilities, dim_, requires_grad=True, device=device)\n",
    "F_base = torch.mean(START_locs, dim=0).repeat(num_facilities, 1).unsqueeze(0).requires_grad_().to(device)\n",
    "F_locs = F_base.expand(num_drones, -1, -1)  # view, shares grad with F_base\n",
    "data = torch.cat((START_locs, F_locs, END_locs), dim=1)  # shape: (Nd, Nf+2, D)\n",
    "print(\"Data Loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute n_routes from each drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.],\n",
      "        [3906.]])\n",
      "log_n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703],\n",
      "        [8.2703]])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "n_drone_routes = torch.tensor(utils.num_flpo_routes(num_facilities, num_drones)[0], dtype=torch.float32).view(-1,1).to(device)\n",
    "print(f\"n_routes:\\t{n_drone_routes.shape}\\n{n_drone_routes}\\nlog_n_routes:\\t{n_drone_routes.shape}\\n{torch.log(n_drone_routes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the VRP NET Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRP NET loaded on:  cpu\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "VRPNet_L                                                               --\n",
      "├─LinearAttnEncoder: 1-1                                               2,560\n",
      "│    └─MultiheadAttention: 2-1                                         197,376\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-1                       65,792\n",
      "│    └─Linear: 2-2                                                     768\n",
      "│    └─Linear: 2-3                                                     8,224\n",
      "│    └─LayerNorm: 2-4                                                  512\n",
      "│    └─Dropout: 2-5                                                    --\n",
      "│    └─ReLU: 2-6                                                       --\n",
      "├─Decoder: 1-2                                                         --\n",
      "│    └─TransformerDecoder: 2-7                                         --\n",
      "│    │    └─ModuleList: 3-2                                            16,992\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "===============================================================================================\n",
      "Total params: 292,224\n",
      "Trainable params: 292,224\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "num_layers_enc = 1\n",
    "num_layers_dec = 1\n",
    "num_heads = 8\n",
    "torch.cuda.empty_cache()\n",
    "vrp_net = VRPNet_L(dim_, hidden_dim, device, num_layers_enc, num_layers_dec, num_heads)\n",
    "if torch.cuda.is_available():\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=True))\n",
    "else:\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=False, map_location=torch.device('cpu')))\n",
    "vrp_net.eval()\n",
    "\n",
    "# for param in vrp_net.parameters():\n",
    "#     param.requires_grad = False\n",
    "print('VRP NET loaded on: ',vrp_net.device)\n",
    "print(summary(vrp_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading lseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs: 3\n",
      "n_outputs: 1\n",
      "layers: [10, 10]\n",
      "io_scale: 1\n",
      "LSE_net:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "dnn                                      --\n",
      "├─ModuleList: 1-1                        --\n",
      "│    └─Linear: 2-1                       (40)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Linear: 2-3                       (110)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       (11)\n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 0\n",
      "Non-trainable params: 161\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(LSE_net)\n",
    "lse_data = torch.load('logSumExp_models/lse_2025_4_25__15_5_32.pth', weights_only=False)\n",
    "n_inputs = lse_data['n_inputs']\n",
    "n_outputs = lse_data['n_outputs']\n",
    "layers = lse_data['layers']\n",
    "weights = lse_data['model_state_dict']\n",
    "io_scale = lse_data['io_scale']\n",
    "lse_net = LSE_net.dnn(n_inputs, n_outputs, layers)\n",
    "lse_net.to(device)\n",
    "lse_net.load_state_dict(weights)\n",
    "lse_net.eval()\n",
    "for p in lse_net.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f'n_inputs: {n_inputs}\\nn_outputs: {n_outputs}\\nlayers: {layers}\\nio_scale: {io_scale}\\nLSE_net:\\n{summary(lse_net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([10,10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSumExp(D_tensor, beta):\n",
    "    # with torch.no_grad():\n",
    "    D_min = torch.min(D_tensor, axis=1, keepdims=True)\n",
    "    F = -1/beta * torch.log(torch.sum(torch.exp(-beta*(D_tensor - D_min.values)), axis=1, keepdims=True)) + 1/beta * torch.log(torch.tensor([D_tensor.shape[1]]))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a random variable matrix with iid entries of shape shape (a,b) between [r1, r2] at uniform using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 3\n",
    "# b = 2\n",
    "# r1 = 0.5\n",
    "# r2 = 10.0\n",
    "# (r1 - r2) * torch.rand(a,b) + r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# with torch.no_grad():\n",
    "#     # forward pass: no activations are saved for grad\n",
    "#     _, actions = vrp_net(data, mod='eval_greedy')\n",
    "# e = time.time()\n",
    "# actions.detach()\n",
    "# d_mins = utils.route_cost(data, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_mins.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     D_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "#     F_tensor = logSumExp(D_tensor, beta=1e-4)\n",
    "# F_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# # len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "# io_scale = lse_data['io_scale']\n",
    "# b_min = 0.1\n",
    "# b_max = 1000\n",
    "# b_grow = 1.1\n",
    "# b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "# drone_id = 1\n",
    "# FreeEnergy = []\n",
    "# betas = []\n",
    "\n",
    "# s = time.time()\n",
    "# with torch.no_grad():\n",
    "#     # forward pass: no activations are saved for grad\n",
    "#     _, actions = vrp_net(data, mod='eval_greedy')\n",
    "# e = time.time()\n",
    "# actions.detach()\n",
    "# d_mins = utils.route_cost(data, actions)[drone_id:drone_id+1]\n",
    "# d_array_est = (d_mins - 1.0) * torch.rand(int(n_drone_routes[drone_id,0])) + 1.0\n",
    "# Fmin_est = logSumExp(d_array_est, b_min)\n",
    "\n",
    "# # beta=b_min\n",
    "# for beta in b_array:\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     In = torch.tensor([\n",
    "#         Fmin_est.to(device),\n",
    "#         io_scale*d_mins,\n",
    "#         torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device)\n",
    "#     ])\n",
    "#     # update annealing parameter\n",
    "#     print(In)\n",
    "#     # print(In[2].detach().numpy())\n",
    "#     betas.append(In[2].detach().numpy())\n",
    "#     # print(betas)\n",
    "#     Out = lse_net(In)/io_scale + d_mins/io_scale - (1/beta * torch.log(n_drone_routes[drone_id,0])).to(device)\n",
    "#     # print(beta, torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])), In, Out)\n",
    "#     # print(In)\n",
    "#     FreeEnergy.append(Out[0].detach().numpy())\n",
    "\n",
    "#     # beta = beta * b_grow\n",
    "    \n",
    "    \n",
    "# plt.figure(figsize=(6,2))\n",
    "# plt.plot(betas, FreeEnergy)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute an estimate of free energy at b_min for all drones using d_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:1.000e-05\n",
      "here0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200;\n",
    "optimizer = optim.Adam([F_base], lr=1e-3)\n",
    "# b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "io_scale = lse_data['io_scale']\n",
    "b_min = 0.00001\n",
    "b_max = 0.00001\n",
    "b_grow = 2\n",
    "b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# beta=b_min\n",
    "for beta in b_array:\n",
    "    print(f\"beta:{beta:.3e}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        s = time.time()\n",
    "        with torch.no_grad():\n",
    "            # forward pass: no activations are saved for grad\n",
    "            _, actions = vrp_net(data, mod='eval_greedy')\n",
    "        e = time.time()\n",
    "        actions.detach()\n",
    "        d_mins = utils.route_cost(data, actions)\n",
    "        print('here0')\n",
    "        with torch.no_grad():\n",
    "            D_bmin_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "            print('here1')\n",
    "            Fmin_tensor = logSumExp(D_bmin_tensor, beta=b_min).to(device)\n",
    "        print('here2')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        In = torch.cat((\n",
    "            Fmin_tensor,\n",
    "            io_scale*d_mins.view(-1,1), \n",
    "            torch.ones((num_drones,1)).to(device)*torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device).to(device)), axis=1) #, torch.ones((num_drones,1)).to(device)*b_min.to(device)),axis=1)\n",
    "        # print(In)\n",
    "        Out = lse_net(In)/io_scale + d_mins.view(-1,1) - (1/beta * torch.log(n_drone_routes)).to(device) \n",
    "        FreeEnergy = torch.mean(Out)\n",
    "        \n",
    "        # print(torch.norm(data))\n",
    "        optimizer.zero_grad()\n",
    "        FreeEnergy.backward()\n",
    "        optimizer.step()\n",
    "        # perturb and update facility location data for each drone\n",
    "        std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "        with torch.no_grad():\n",
    "            F_base += torch.normal(mean=torch.zeros(1,num_facilities,dim_), std=0.000*torch.ones(1,num_facilities,dim_)).to(device)\n",
    "        # print(F_base)\n",
    "        F_locs = F_base.expand(num_drones, -1, -1)\n",
    "        # print(F_locs)\n",
    "        data = torch.cat((START_locs, F_locs, END_locs), dim=1)\n",
    "        if epoch % 1 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"\\tEpoch: {epoch}\\tVRP_runtime: {e-s:.2f}s\\tFreeEnergy: {FreeEnergy:.2f}\\tF_Grad: {torch.max(torch.abs(F_base.grad)):.3e}\\td_min_mean: {torch.mean(d_mins):.2f}\")\n",
    "    # update annealing parameter\n",
    "    beta = beta * b_grow\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15947b4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_locs = START_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(start_locs[:,0],start_locs[:,1],color='cyan',marker='.')\n",
    "end_locs = END_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(end_locs[:,0],end_locs[:,1],color='red',marker='.')\n",
    "f_locs = F_base.squeeze(0).detach().cpu().numpy()\n",
    "plt.scatter(f_locs[:,0],f_locs[:,1],color='black',marker='^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this block shoud be dF/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate $\\frac{\\partial F}{\\partial d_{min}}$ (code in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/ndxykdmj1q9cwr2kpvkvcbs80000gn/T/ipykernel_89473/1274708057.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  d_mins_torch.grad\n"
     ]
    }
   ],
   "source": [
    "# fix beta\n",
    "b = np.random.choice(b_arr)\n",
    "d_mins_torch = torch.tensor(d_mins, dtype=torch.float32, requires_grad=True).view(-1,1)\n",
    "const_bmin = -io_scale/b_arr[0] * np.log(len_Darray) * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "const_b = b * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "In = torch.concatenate((const_bmin, d_mins_torch, const_b), axis=1)\n",
    "Out = lse_net(In)\n",
    "# print(Out)\n",
    "Out[0].retain_grad()\n",
    "Out[0].backward()\n",
    "d_mins_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CLF to determin Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GD code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the Beta Loop for Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False, False,  True, False, False, False, False])\n",
      "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Filtered: tensor([ 0,  5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(20)  # Just an example tensor: [0, 1, 2, ..., 19]\n",
    "\n",
    "# Create a mask to skip every 5th element\n",
    "mask = torch.zeros(len(x), dtype=bool)\n",
    "mask[0::5] = True  # Set every 5th element to False\n",
    "print(mask)\n",
    "result = x[mask]\n",
    "\n",
    "print(\"Original:\", x)\n",
    "print(\"Filtered:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
