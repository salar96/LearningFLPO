{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning FLPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we will implement the hierarchical ML architecture to predict the parameters in the FLPO setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from VRP_Net_L import VRPNet_L\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import LSE_net\n",
    "from torch import optim\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2545, 0.3607])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.tensor([0.3,0.3]), std=torch.tensor([0.1,0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n",
      "Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed=42;\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Running on: \" , device)\n",
    "num_drones = 100 # number of FLPO instances\n",
    "num_facilities = 4\n",
    "dim_ = 2\n",
    "# START and END locations: no grads needed\n",
    "nd_per_cluster = int(num_drones/2)\n",
    "means1 = torch.tensor([[0.4,0.7]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "means2 = torch.tensor([[0.7,0.3]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "std2 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "START_locs1 = torch.normal(mean=means1, std=std1)\n",
    "START_locs2 = torch.normal(mean=means2, std=std2)\n",
    "START_locs = torch.cat((START_locs1, START_locs2), axis=0)\n",
    "END_locs   = torch.ones((num_drones, 1, dim_), requires_grad=False, device=device)#torch.rand(num_drones, 1, dim_, requires_grad=False, device=device)\n",
    "\n",
    "# Facility locations: we want grads here\n",
    "# We create a base tensor with requires_grad=True, then expand it\n",
    "# F_base = torch.rand(1, num_facilities, dim_, requires_grad=True, device=device)\n",
    "F_base = torch.mean(START_locs, dim=0).repeat(num_facilities, 1).unsqueeze(0).requires_grad_().to(device)\n",
    "F_locs = F_base.expand(num_drones, -1, -1)  # view, shares grad with F_base\n",
    "data = torch.cat((START_locs, F_locs, END_locs), dim=1)  # shape: (Nd, Nf+2, D)\n",
    "print(\"Data Loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute n_routes from each drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.],\n",
      "        [341.]])\n",
      "log_n_routes:\ttorch.Size([100, 1])\n",
      "tensor([[5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319],\n",
      "        [5.8319]])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "n_drone_routes = torch.tensor(utils.num_flpo_routes(num_facilities, num_drones)[0], dtype=torch.float32).view(-1,1).to(device)\n",
    "print(f\"n_routes:\\t{n_drone_routes.shape}\\n{n_drone_routes}\\nlog_n_routes:\\t{n_drone_routes.shape}\\n{torch.log(n_drone_routes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the VRP NET Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRP NET loaded on:  cpu\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "VRPNet_L                                                               --\n",
      "├─LinearAttnEncoder: 1-1                                               2,560\n",
      "│    └─MultiheadAttention: 2-1                                         197,376\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-1                       65,792\n",
      "│    └─Linear: 2-2                                                     768\n",
      "│    └─Linear: 2-3                                                     8,224\n",
      "│    └─LayerNorm: 2-4                                                  512\n",
      "│    └─Dropout: 2-5                                                    --\n",
      "│    └─ReLU: 2-6                                                       --\n",
      "├─Decoder: 1-2                                                         --\n",
      "│    └─TransformerDecoder: 2-7                                         --\n",
      "│    │    └─ModuleList: 3-2                                            16,992\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "===============================================================================================\n",
      "Total params: 292,224\n",
      "Trainable params: 292,224\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "num_layers_enc = 1\n",
    "num_layers_dec = 1\n",
    "num_heads = 8\n",
    "torch.cuda.empty_cache()\n",
    "vrp_net = VRPNet_L(dim_, hidden_dim, device, num_layers_enc, num_layers_dec, num_heads)\n",
    "if torch.cuda.is_available():\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=True))\n",
    "else:\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=False, map_location=torch.device('cpu')))\n",
    "vrp_net.eval()\n",
    "\n",
    "# for param in vrp_net.parameters():\n",
    "#     param.requires_grad = False\n",
    "print('VRP NET loaded on: ',vrp_net.device)\n",
    "print(summary(vrp_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading lseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs: 3\n",
      "n_outputs: 1\n",
      "layers: [20, 20, 10]\n",
      "io_scale: 1\n",
      "LSE_net:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "dnn                                      --\n",
      "├─ModuleList: 1-1                        --\n",
      "│    └─Linear: 2-1                       (80)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Linear: 2-3                       (420)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       (210)\n",
      "│    └─ReLU: 2-6                         --\n",
      "│    └─Linear: 2-7                       (11)\n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 0\n",
      "Non-trainable params: 721\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(LSE_net)\n",
    "lse_data = torch.load('logSumExp_models/lse_2025_4_30__14_6_10.pth', weights_only=False)\n",
    "n_inputs = lse_data['n_inputs']\n",
    "n_outputs = lse_data['n_outputs']\n",
    "layers = lse_data['layers']\n",
    "weights = lse_data['model_state_dict']\n",
    "io_scale = lse_data['io_scale']\n",
    "lse_net = LSE_net.dnn(n_inputs, n_outputs, layers)\n",
    "lse_net.to(device)\n",
    "lse_net.load_state_dict(weights)\n",
    "lse_net.eval()\n",
    "for p in lse_net.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f'n_inputs: {n_inputs}\\nn_outputs: {n_outputs}\\nlayers: {layers}\\nio_scale: {io_scale}\\nLSE_net:\\n{summary(lse_net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([10,10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSumExp(D_tensor, beta):\n",
    "    # with torch.no_grad():\n",
    "    # print(D_tensor)\n",
    "    D_min = torch.min(D_tensor, axis=1, keepdims=True)\n",
    "    F = -1/beta * torch.log(torch.sum(torch.exp(-beta*(D_tensor - D_min.values)), axis=1, keepdims=True)) + 1/beta * torch.log(torch.tensor([D_tensor.shape[1]])) + D_min.values\n",
    "    return F\n",
    "\n",
    "def area_approx_F(D_min, D_max_range, N_D, beta):\n",
    "    min_beta_D_arr = beta * D_min\n",
    "    x_max = beta * D_max_range - min_beta_D_arr\n",
    "    F_est = -1/beta * np.log(N_D/x_max * (1 - np.exp(-x_max))) + D_min + 1/beta * np.log(N_D)\n",
    "    return F_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a random variable matrix with iid entries of shape shape (a,b) between [r1, r2] at uniform using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 3\n",
    "# b = 2\n",
    "# r1 = 0.5\n",
    "# r2 = 10.0\n",
    "# (r1 - r2) * torch.rand(a,b) + r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "with torch.no_grad():\n",
    "    # forward pass: no activations are saved for grad\n",
    "    _, actions = vrp_net(data, mod='eval_greedy')\n",
    "e = time.time()\n",
    "actions.detach()\n",
    "d_mins = utils.route_cost(data, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5197],\n",
       "        [0.4645],\n",
       "        [0.4761],\n",
       "        [0.4811],\n",
       "        [0.5550],\n",
       "        [0.4888],\n",
       "        [0.5065],\n",
       "        [0.5331],\n",
       "        [0.4845],\n",
       "        [0.5212],\n",
       "        [0.5403],\n",
       "        [0.5335],\n",
       "        [0.5189],\n",
       "        [0.5264],\n",
       "        [0.5088],\n",
       "        [0.5265],\n",
       "        [0.5147],\n",
       "        [0.5479],\n",
       "        [0.4925],\n",
       "        [0.4871],\n",
       "        [0.5546],\n",
       "        [0.5087],\n",
       "        [0.5787],\n",
       "        [0.5175],\n",
       "        [0.5084],\n",
       "        [0.5141],\n",
       "        [0.5384],\n",
       "        [0.5053],\n",
       "        [0.5305],\n",
       "        [0.5194],\n",
       "        [0.5495],\n",
       "        [0.5563],\n",
       "        [0.5069],\n",
       "        [0.4953],\n",
       "        [0.4961],\n",
       "        [0.5510],\n",
       "        [0.5177],\n",
       "        [0.5123],\n",
       "        [0.4858],\n",
       "        [0.5358],\n",
       "        [0.4982],\n",
       "        [0.5182],\n",
       "        [0.5082],\n",
       "        [0.4838],\n",
       "        [0.5272],\n",
       "        [0.4954],\n",
       "        [0.5291],\n",
       "        [0.4990],\n",
       "        [0.5236],\n",
       "        [0.5124],\n",
       "        [0.5260],\n",
       "        [0.4993],\n",
       "        [0.6023],\n",
       "        [0.5409],\n",
       "        [0.5285],\n",
       "        [0.5196],\n",
       "        [0.4973],\n",
       "        [0.5195],\n",
       "        [0.4857],\n",
       "        [0.5153],\n",
       "        [0.5114],\n",
       "        [0.5010],\n",
       "        [0.4909],\n",
       "        [0.4936],\n",
       "        [0.5198],\n",
       "        [0.5110],\n",
       "        [0.5242],\n",
       "        [0.5032],\n",
       "        [0.5798],\n",
       "        [0.4831],\n",
       "        [0.5015],\n",
       "        [0.4850],\n",
       "        [0.5181],\n",
       "        [0.4986],\n",
       "        [0.5367],\n",
       "        [0.5441],\n",
       "        [0.5394],\n",
       "        [0.5047],\n",
       "        [0.4829],\n",
       "        [0.4966],\n",
       "        [0.5988],\n",
       "        [0.5041],\n",
       "        [0.5428],\n",
       "        [0.5126],\n",
       "        [0.5015],\n",
       "        [0.5162],\n",
       "        [0.5916],\n",
       "        [0.5139],\n",
       "        [0.5140],\n",
       "        [0.5103],\n",
       "        [0.4934],\n",
       "        [0.4995],\n",
       "        [0.5116],\n",
       "        [0.5744],\n",
       "        [0.4893],\n",
       "        [0.5132],\n",
       "        [0.5348],\n",
       "        [0.5195],\n",
       "        [0.5222],\n",
       "        [0.5392]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mins.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7677],\n",
       "        [0.7311],\n",
       "        [0.7429],\n",
       "        [0.7362],\n",
       "        [0.7811],\n",
       "        [0.7370],\n",
       "        [0.7528],\n",
       "        [0.7598],\n",
       "        [0.7268],\n",
       "        [0.7637],\n",
       "        [0.7753],\n",
       "        [0.7720],\n",
       "        [0.7421],\n",
       "        [0.7562],\n",
       "        [0.7546],\n",
       "        [0.7651],\n",
       "        [0.7506],\n",
       "        [0.7912],\n",
       "        [0.7503],\n",
       "        [0.7412],\n",
       "        [0.7703],\n",
       "        [0.7519],\n",
       "        [0.7924],\n",
       "        [0.7640],\n",
       "        [0.7670],\n",
       "        [0.7620],\n",
       "        [0.7836],\n",
       "        [0.7446],\n",
       "        [0.7592],\n",
       "        [0.7684],\n",
       "        [0.7684],\n",
       "        [0.7789],\n",
       "        [0.7503],\n",
       "        [0.7495],\n",
       "        [0.7580],\n",
       "        [0.7746],\n",
       "        [0.7535],\n",
       "        [0.7667],\n",
       "        [0.7448],\n",
       "        [0.7630],\n",
       "        [0.7456],\n",
       "        [0.7657],\n",
       "        [0.7638],\n",
       "        [0.7454],\n",
       "        [0.7619],\n",
       "        [0.7518],\n",
       "        [0.7696],\n",
       "        [0.7615],\n",
       "        [0.7580],\n",
       "        [0.7556],\n",
       "        [0.7644],\n",
       "        [0.7427],\n",
       "        [0.7986],\n",
       "        [0.7803],\n",
       "        [0.7564],\n",
       "        [0.7581],\n",
       "        [0.7369],\n",
       "        [0.7610],\n",
       "        [0.7400],\n",
       "        [0.7703],\n",
       "        [0.7555],\n",
       "        [0.7529],\n",
       "        [0.7449],\n",
       "        [0.7515],\n",
       "        [0.7668],\n",
       "        [0.7464],\n",
       "        [0.7660],\n",
       "        [0.7458],\n",
       "        [0.7826],\n",
       "        [0.7534],\n",
       "        [0.7439],\n",
       "        [0.7327],\n",
       "        [0.7725],\n",
       "        [0.7370],\n",
       "        [0.7597],\n",
       "        [0.7789],\n",
       "        [0.7664],\n",
       "        [0.7596],\n",
       "        [0.7489],\n",
       "        [0.7391],\n",
       "        [0.7982],\n",
       "        [0.7466],\n",
       "        [0.7637],\n",
       "        [0.7474],\n",
       "        [0.7561],\n",
       "        [0.7588],\n",
       "        [0.8066],\n",
       "        [0.7565],\n",
       "        [0.7604],\n",
       "        [0.7491],\n",
       "        [0.7367],\n",
       "        [0.7435],\n",
       "        [0.7473],\n",
       "        [0.7898],\n",
       "        [0.7472],\n",
       "        [0.7489],\n",
       "        [0.7697],\n",
       "        [0.7666],\n",
       "        [0.7452],\n",
       "        [0.7739]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    D_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "    F_tensor = logSumExp(D_tensor, beta=1e-4)\n",
    "F_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m d_mins \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mroute_cost(data, actions)[drone_id:drone_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# d_array_est = (d_mins - 1.0) * torch.rand(1,int(n_drone_routes[drone_id,0])) + 1.0\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Fmin_est = logSumExp(d_array_est, b_min)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m Fmin_est \u001b[38;5;241m=\u001b[39m \u001b[43marea_approx_F\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_max_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_drone_routes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdrone_id\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_min\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(Fmin_est)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# beta=b_min\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# for beta in b_array:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# plt.grid()\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36marea_approx_F\u001b[0;34m(D_min, D_max_range, N_D, beta)\u001b[0m\n\u001b[1;32m      9\u001b[0m min_beta_D_arr \u001b[38;5;241m=\u001b[39m beta \u001b[38;5;241m*\u001b[39m D_min\n\u001b[1;32m     10\u001b[0m x_max \u001b[38;5;241m=\u001b[39m beta \u001b[38;5;241m*\u001b[39m D_max_range \u001b[38;5;241m-\u001b[39m min_beta_D_arr\n\u001b[0;32m---> 11\u001b[0m F_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mbeta \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(N_D\u001b[38;5;241m/\u001b[39mx_max \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx_max\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m+\u001b[39m D_min \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mbeta \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(N_D)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_est\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:1194\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "io_scale = lse_data['io_scale']\n",
    "b_min = 0.01\n",
    "b_max = 10000\n",
    "b_grow = 1.01\n",
    "b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "drone_id = 1\n",
    "FreeEnergy = []\n",
    "betas = []\n",
    "\n",
    "s = time.time()\n",
    "with torch.no_grad():\n",
    "    # forward pass: no activations are saved for grad\n",
    "    _, actions = vrp_net(data, mod='eval_greedy')\n",
    "e = time.time()\n",
    "actions.detach()\n",
    "d_mins = utils.route_cost(data, actions)[drone_id:drone_id+1]\n",
    "# d_array_est = (d_mins - 1.0) * torch.rand(1,int(n_drone_routes[drone_id,0])) + 1.0\n",
    "# Fmin_est = logSumExp(d_array_est, b_min)\n",
    "Fmin_est = area_approx_F(d_mins, D_max_range=1.0, N_D=int(n_drone_routes[drone_id,0]), beta=b_min)\n",
    "print(Fmin_est)\n",
    "# beta=b_min\n",
    "# for beta in b_array:\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     In = torch.tensor([\n",
    "#         Fmin_est.to(device),\n",
    "#         io_scale*d_mins,\n",
    "#         torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device)\n",
    "#     ])\n",
    "#     # update annealing parameter\n",
    "#     print(In)\n",
    "#     # print(In[2].detach().numpy())\n",
    "#     betas.append(In[2].detach().numpy())\n",
    "#     # print(betas)\n",
    "#     Out = lse_net(In)/io_scale - 0*(1/beta * torch.log(n_drone_routes[drone_id,0])).to(device)\n",
    "#     # print(beta, torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])), In, Out)\n",
    "#     # print(In)\n",
    "#     FreeEnergy.append(Out[0].detach().numpy())\n",
    "\n",
    "#     # beta = beta * b_grow\n",
    "    \n",
    "    \n",
    "# plt.figure(figsize=(6,2))\n",
    "# plt.plot(betas, FreeEnergy)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute an estimate of free energy at b_min for all drones using d_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:1.000e-04\n",
      "\tEpoch: 0\tVRP_runtime: 0.03s\tFreeEnergy: 1.27\tF_Grad: 9.160e-01\td_min_mean: 0.52\n",
      "\tEpoch: 50\tVRP_runtime: 0.01s\tFreeEnergy: 1.12\tF_Grad: 7.841e-01\td_min_mean: 0.42\n",
      "\tEpoch: 100\tVRP_runtime: 0.02s\tFreeEnergy: 1.02\tF_Grad: 6.493e-01\td_min_mean: 0.35\n",
      "\tEpoch: 150\tVRP_runtime: 0.02s\tFreeEnergy: 0.94\tF_Grad: 5.481e-01\td_min_mean: 0.30\n",
      "\tEpoch: 200\tVRP_runtime: 0.03s\tFreeEnergy: 0.89\tF_Grad: 4.486e-01\td_min_mean: 0.27\n",
      "\tEpoch: 250\tVRP_runtime: 0.02s\tFreeEnergy: 0.85\tF_Grad: 3.595e-01\td_min_mean: 0.24\n",
      "\tEpoch: 300\tVRP_runtime: 0.02s\tFreeEnergy: 0.82\tF_Grad: 2.787e-01\td_min_mean: 0.22\n",
      "\tEpoch: 350\tVRP_runtime: 0.02s\tFreeEnergy: 0.81\tF_Grad: 2.133e-01\td_min_mean: 0.21\n",
      "\tEpoch: 399\tVRP_runtime: 0.02s\tFreeEnergy: 0.79\tF_Grad: 1.596e-01\td_min_mean: 0.21\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400;\n",
    "optimizer = optim.Adam([F_base], lr=1e-3)\n",
    "# b_arr = torch.tensor(lse_data['b_arr'], dtype=torch.float32)\n",
    "# len_Darray = torch.tensor(lse_data['len_Darray'], dtype=torch.float32)\n",
    "io_scale = lse_data['io_scale']\n",
    "b_min = 1e-4\n",
    "b_max = 1e-4\n",
    "b_grow = 2\n",
    "b_array = utils.createBetaArray(b_min, b_max, b_grow).to(device)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# beta=b_min\n",
    "for beta in b_array:\n",
    "    print(f\"beta:{beta:.3e}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        s = time.time()\n",
    "        with torch.no_grad():\n",
    "            # forward pass: no activations are saved for grad\n",
    "            _, actions = vrp_net(data, mod='eval_greedy')\n",
    "        e = time.time()\n",
    "        actions.detach()\n",
    "        d_mins = utils.route_cost(data, actions)\n",
    "        # print('here0')\n",
    "        with torch.no_grad():\n",
    "            D_bmin_tensor = (d_mins.view(-1,1) - 1.0) * torch.rand(num_drones, int(n_drone_routes[0,0])) + 1.0\n",
    "            # print('here1')\n",
    "            Fmin_tensor = logSumExp(D_bmin_tensor, beta=b_min).to(device)\n",
    "        # print('here2')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        In = torch.cat((\n",
    "            Fmin_tensor,\n",
    "            io_scale*d_mins.view(-1,1), \n",
    "            torch.ones((num_drones,1)).to(device)*torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0])).to(device).to(device)), axis=1) #, torch.ones((num_drones,1)).to(device)*b_min.to(device)),axis=1)\n",
    "        # print(In)\n",
    "        Out = lse_net(In)/io_scale + d_mins.view(-1,1) #- (1/beta * torch.log(n_drone_routes)).to(device) \n",
    "        FreeEnergy = torch.mean(Out)\n",
    "        \n",
    "        # print(torch.norm(data))\n",
    "        optimizer.zero_grad()\n",
    "        FreeEnergy.backward()\n",
    "        optimizer.step()\n",
    "        # perturb and update facility location data for each drone\n",
    "        std1 = torch.tensor([[0.05,0.05]]).repeat(nd_per_cluster,1).unsqueeze(1).to(device)\n",
    "        with torch.no_grad():\n",
    "            F_base += torch.normal(mean=torch.zeros(1,num_facilities,dim_), std=0.0001*torch.ones(1,num_facilities,dim_)).to(device)\n",
    "        # print(F_base)\n",
    "        F_locs = F_base.expand(num_drones, -1, -1)\n",
    "        # print(F_locs)\n",
    "        data = torch.cat((START_locs, F_locs, END_locs), dim=1)\n",
    "        if epoch % 50 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"\\tEpoch: {epoch}\\tVRP_runtime: {e-s:.2f}s\\tFreeEnergy: {FreeEnergy:.2f}\\tF_Grad: {torch.max(torch.abs(F_base.grad)):.3e}\\td_min_mean: {torch.mean(d_mins):.2f}\")\n",
    "    # update annealing parameter\n",
    "    beta = beta * b_grow\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x31866a160>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_locs = START_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(start_locs[:,0],start_locs[:,1],color='cyan',marker='.')\n",
    "end_locs = END_locs.squeeze(1).cpu().numpy()\n",
    "plt.scatter(end_locs[:,0],end_locs[:,1],color='red',marker='.')\n",
    "f_locs = F_base.squeeze(0).detach().cpu().numpy()\n",
    "plt.scatter(f_locs[:,0],f_locs[:,1],color='black',marker='^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this block shoud be dF/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate $\\frac{\\partial F}{\\partial d_{min}}$ (code in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/ndxykdmj1q9cwr2kpvkvcbs80000gn/T/ipykernel_89473/1274708057.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  d_mins_torch.grad\n"
     ]
    }
   ],
   "source": [
    "# fix beta\n",
    "b = np.random.choice(b_arr)\n",
    "d_mins_torch = torch.tensor(d_mins, dtype=torch.float32, requires_grad=True).view(-1,1)\n",
    "const_bmin = -io_scale/b_arr[0] * np.log(len_Darray) * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "const_b = b * torch.ones(len(d_mins), dtype=torch.float32).view(-1,1)\n",
    "In = torch.concatenate((const_bmin, d_mins_torch, const_b), axis=1)\n",
    "Out = lse_net(In)\n",
    "# print(Out)\n",
    "Out[0].retain_grad()\n",
    "Out[0].backward()\n",
    "d_mins_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CLF to determin Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GD code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the Beta Loop for Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False, False,  True, False, False, False, False])\n",
      "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Filtered: tensor([ 0,  5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(20)  # Just an example tensor: [0, 1, 2, ..., 19]\n",
    "\n",
    "# Create a mask to skip every 5th element\n",
    "mask = torch.zeros(len(x), dtype=bool)\n",
    "mask[0::5] = True  # Set every 5th element to False\n",
    "print(mask)\n",
    "result = x[mask]\n",
    "\n",
    "print(\"Original:\", x)\n",
    "print(\"Filtered:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
