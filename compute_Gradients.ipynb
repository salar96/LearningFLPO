{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from VRP_Net_L import VRPNet_L\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import LSE_net\n",
    "from torch import optim\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n"
     ]
    }
   ],
   "source": [
    "seed=41;\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "np.random.seed(seed)\n",
    "print(\"Running on: \" , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_drones = 100\tnum_facilities = 100\tdim = 2\n",
      "Data Loaded.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UAV FLPO MetaData\n",
    "num_drones = 100\n",
    "n_drone_clusters = 5\n",
    "drone_cluster_split = np.random.uniform(0.0, 1.0, n_drone_clusters)\n",
    "drone_cluster_split = drone_cluster_split / np.sum(drone_cluster_split)\n",
    "num_facilities = 100\n",
    "dim_ = 2\n",
    "print(f'num_drones = {num_drones}\\tnum_facilities = {num_facilities}\\tdim = {dim_}')\n",
    "\n",
    "# Assign start location to each drone\n",
    "drone_cnt = 0\n",
    "for i in range(n_drone_clusters):\n",
    "    if i == n_drone_clusters-1:\n",
    "        n_drones = int(num_drones - drone_cnt)\n",
    "    else:\n",
    "        n_drones = int(drone_cluster_split[i] * (num_drones+1))\n",
    "        drone_cnt += n_drones\n",
    "\n",
    "    drone_cluster_mean = torch.rand(1, dim_).repeat(n_drones,1).unsqueeze(1).to(device)\n",
    "    drone_cluster_std = ((0.02 - 0.08) * torch.rand(1,dim_) + 0.08).repeat(n_drones,1).unsqueeze(1).to(device)\n",
    "    drone_cluster_START_locs = torch.normal(mean=drone_cluster_mean, std=drone_cluster_std)\n",
    "    if i == 0:\n",
    "        START_locs = drone_cluster_START_locs\n",
    "    else:\n",
    "        START_locs = torch.cat((START_locs, drone_cluster_START_locs), axis=0)\n",
    "\n",
    "START_locs.shape\n",
    "\n",
    "# Assign destination location to each drone\n",
    "END_locs = torch.ones((num_drones, 1, dim_), requires_grad=False, device=device) #torch.rand(num_drones, 1, dim_, requires_grad=False, device=device)\n",
    "\n",
    "# Create the data tensor\n",
    "F_base = torch.mean(START_locs, dim=0).repeat(num_facilities, 1).unsqueeze(0).requires_grad_().to(device)\n",
    "F_locs = F_base.expand(num_drones, -1, -1)  # view, shares grad with F_base\n",
    "data = torch.cat((START_locs, F_locs, END_locs), dim=1)  # shape: (Nd, Nf+2, D)\n",
    "print(\"Data Loaded.\")\n",
    "\n",
    "# plot the data\n",
    "def plot_UAV_FLPO(drone_START, drone_END, Facilities, figuresize=(6,5)):\n",
    "    start_locs = drone_START.squeeze(1).cpu().numpy()\n",
    "    end_locs = drone_END.squeeze(1).cpu().numpy()\n",
    "    f_locs = Facilities.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=figuresize)\n",
    "    plt.scatter(start_locs[:,0], start_locs[:,1], color='violet', marker='X', alpha=0.5)\n",
    "    plt.scatter(end_locs[:,0], end_locs[:,1], color='red', marker='.')\n",
    "    plt.scatter(f_locs[:,0], f_locs[:,1], color='black', marker='^')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_UAV_FLPO(START_locs, END_locs, F_base, (4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the VRP NET Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRP NET loaded on:  cpu\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "VRPNet_L                                                               --\n",
      "├─LinearAttnEncoder: 1-1                                               2,560\n",
      "│    └─MultiheadAttention: 2-1                                         197,376\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-1                       65,792\n",
      "│    └─Linear: 2-2                                                     768\n",
      "│    └─Linear: 2-3                                                     8,224\n",
      "│    └─LayerNorm: 2-4                                                  512\n",
      "│    └─Dropout: 2-5                                                    --\n",
      "│    └─ReLU: 2-6                                                       --\n",
      "├─Decoder: 1-2                                                         --\n",
      "│    └─TransformerDecoder: 2-7                                         --\n",
      "│    │    └─ModuleList: 3-2                                            16,992\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "===============================================================================================\n",
      "Total params: 292,224\n",
      "Trainable params: 292,224\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "num_layers_enc = 1\n",
    "num_layers_dec = 1\n",
    "num_heads = 8\n",
    "torch.cuda.empty_cache()\n",
    "vrp_net = VRPNet_L(dim_, hidden_dim, device, num_layers_enc, num_layers_dec, num_heads)\n",
    "if torch.cuda.is_available():\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=True))\n",
    "else:\n",
    "    vrp_net.load_state_dict(torch.load('Saved models/POMO2025_04_12 00_54_260.6350972652435303best_model.pth',weights_only=False, map_location=torch.device('cpu')))\n",
    "vrp_net.eval()\n",
    "\n",
    "# for param in vrp_net.parameters():\n",
    "#     param.requires_grad = False\n",
    "print('VRP NET loaded on: ',vrp_net.device)\n",
    "print(summary(vrp_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "with torch.no_grad():\n",
    "    # forward pass: no activations are saved for grad\n",
    "    _, actions = vrp_net(data, mod='eval_greedy')\n",
    "e = time.time()\n",
    "actions.detach()\n",
    "d_mins = utils.route_cost(data, actions).view(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7283],\n",
       "        [0.6469],\n",
       "        [0.7067],\n",
       "        [0.6909],\n",
       "        [0.7056],\n",
       "        [0.6857],\n",
       "        [0.7080],\n",
       "        [0.6315],\n",
       "        [0.7272],\n",
       "        [0.6695],\n",
       "        [0.7424],\n",
       "        [0.6665],\n",
       "        [0.6520],\n",
       "        [0.6725],\n",
       "        [0.7705],\n",
       "        [0.7192],\n",
       "        [0.6938],\n",
       "        [0.6847],\n",
       "        [0.7330],\n",
       "        [0.6921],\n",
       "        [0.6533],\n",
       "        [0.6699],\n",
       "        [1.1451],\n",
       "        [0.7209],\n",
       "        [0.7521],\n",
       "        [1.1873],\n",
       "        [0.5887],\n",
       "        [0.5899],\n",
       "        [0.5743],\n",
       "        [0.5814],\n",
       "        [0.5756],\n",
       "        [0.6015],\n",
       "        [0.5707],\n",
       "        [0.5633],\n",
       "        [0.5748],\n",
       "        [0.5642],\n",
       "        [0.5895],\n",
       "        [0.6145],\n",
       "        [0.5754],\n",
       "        [0.5778],\n",
       "        [0.5747],\n",
       "        [0.5876],\n",
       "        [0.5727],\n",
       "        [0.5869],\n",
       "        [0.5594],\n",
       "        [0.5640],\n",
       "        [0.5770],\n",
       "        [0.5851],\n",
       "        [0.5854],\n",
       "        [0.5738],\n",
       "        [0.5947],\n",
       "        [0.5926],\n",
       "        [0.2573],\n",
       "        [0.5725],\n",
       "        [0.5681],\n",
       "        [0.5787],\n",
       "        [0.5645],\n",
       "        [0.5641],\n",
       "        [0.5870],\n",
       "        [0.5744],\n",
       "        [0.5613],\n",
       "        [0.5816],\n",
       "        [0.5746],\n",
       "        [0.5938],\n",
       "        [0.5561],\n",
       "        [0.5647],\n",
       "        [0.2596],\n",
       "        [0.5748],\n",
       "        [0.5620],\n",
       "        [0.5684],\n",
       "        [0.5563],\n",
       "        [0.5604],\n",
       "        [0.5991],\n",
       "        [0.5721],\n",
       "        [0.5577],\n",
       "        [0.5667],\n",
       "        [0.5598],\n",
       "        [0.5624],\n",
       "        [0.5612],\n",
       "        [0.5803],\n",
       "        [0.5762],\n",
       "        [0.5625],\n",
       "        [0.5724],\n",
       "        [0.5716],\n",
       "        [0.5833],\n",
       "        [0.5751],\n",
       "        [0.0868],\n",
       "        [0.0734],\n",
       "        [0.0957],\n",
       "        [0.6193],\n",
       "        [0.6218],\n",
       "        [0.6139],\n",
       "        [0.6437],\n",
       "        [0.5914],\n",
       "        [0.8520],\n",
       "        [0.6323],\n",
       "        [0.8191],\n",
       "        [0.8476],\n",
       "        [0.6732],\n",
       "        [0.6466]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $\\frac{\\partial d_{min}}{\\partial F_{base}}$, where $d_{min}$ is the shortest path obtained using VRP net for a given set of facility locations $F_{base}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5781,  0.6041],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [-0.9128, -1.1751]],\n",
       " \n",
       "         [[ 0.5930,  0.1474],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [-0.9128, -1.1751]],\n",
       " \n",
       "         [[ 0.5370,  0.5697],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [-0.9128, -1.1751]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]]], grad_fn=<SliceBackward0>),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient0 = torch.autograd.grad(outputs=d_mins, inputs=F_locs,\n",
    "                               grad_outputs=torch.ones_like(d_mins),\n",
    "                               create_graph=True)\n",
    "gradient0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LSE net module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs: 3\n",
      "n_outputs: 1\n",
      "layers: [20, 20, 10]\n",
      "io_scale: 1\n",
      "LSE_net:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "dnn                                      --\n",
      "├─ModuleList: 1-1                        --\n",
      "│    └─Linear: 2-1                       (80)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Linear: 2-3                       (420)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       (210)\n",
      "│    └─ReLU: 2-6                         --\n",
      "│    └─Linear: 2-7                       (11)\n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 0\n",
      "Non-trainable params: 721\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(LSE_net)\n",
    "lse_data = torch.load('logSumExp_models/lse_2025_5_1__17_6_31.pth', weights_only=False)\n",
    "n_inputs = lse_data['n_inputs']\n",
    "n_outputs = lse_data['n_outputs']\n",
    "layers = lse_data['layers']\n",
    "weights = lse_data['model_state_dict']\n",
    "io_scale = lse_data['io_scale']\n",
    "lse_net = LSE_net.dnn(n_inputs, n_outputs, layers)\n",
    "# lse_net.to(device)\n",
    "lse_net.load_state_dict(weights)\n",
    "lse_net.eval()\n",
    "for p in lse_net.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f'n_inputs: {n_inputs}\\nn_outputs: {n_outputs}\\nlayers: {layers}\\nio_scale: {io_scale}\\nLSE_net:\\n{summary(lse_net)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions for free energy approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSumExp(D_tensor, beta):\n",
    "    # with torch.no_grad():\n",
    "    # print(D_tensor)\n",
    "    D_min = torch.min(D_tensor, axis=1, keepdims=True)\n",
    "    F = -1/beta * torch.log(torch.sum(torch.exp(-beta*(D_tensor - D_min.values)), axis=1, keepdims=True)) + 1/beta * torch.log(torch.tensor([D_tensor.shape[1]])) + D_min.values\n",
    "    return F\n",
    "\n",
    "def area_approx_F(D_min, D_max_range, beta, printCalculations=False):\n",
    "    min_beta_D_arr = beta * D_min\n",
    "    x_max = beta * D_max_range - min_beta_D_arr\n",
    "    F_est = -1/beta * torch.log(1/x_max * (1 - torch.exp(-x_max))) + D_min\n",
    "    \n",
    "    if printCalculations:\n",
    "        print(f'min_beta_D_arr:{min_beta_D_arr}')\n",
    "        print(f'x_max:{x_max}')\n",
    "        print(f'inside_log:{1/x_max * (1 - torch.exp(-x_max))}')\n",
    "        print(f'log:{torch.log(1/x_max * (1 - torch.exp(-x_max)))}')\n",
    "        print(f'-1/beta_log:\\n{-1/beta * torch.log(1/x_max * (1 - torch.exp(-x_max)))}')\n",
    "        \n",
    "    return F_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_min = 1e-3\n",
    "beta = 1e-3\n",
    "d_mins = utils.route_cost(data, actions).view(-1,1)#[drone_id:drone_id+1]\n",
    "Fmin_est = area_approx_F(d_mins, D_max_range=2.0, beta=b_min, printCalculations=False)\n",
    "# torch.cuda.empty_cache()\n",
    "In_lse = torch.cat((\n",
    "    Fmin_est.to(device),\n",
    "    io_scale * d_mins,\n",
    "    (torch.ones(d_mins.shape)*torch.log(torch.tensor([beta]))/torch.log(torch.tensor([10.0]))).to(device)\n",
    "), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3660,  0.7283, -3.0000],\n",
       "        [ 1.3096,  0.6469, -3.0000],\n",
       "        [ 1.3611,  0.7067, -3.0000],\n",
       "        [ 1.3637,  0.6909, -3.0000],\n",
       "        [ 1.3445,  0.7056, -3.0000],\n",
       "        [ 1.3563,  0.6857, -3.0000],\n",
       "        [ 1.3348,  0.7080, -3.0000],\n",
       "        [ 1.3060,  0.6315, -3.0000],\n",
       "        [ 1.3435,  0.7272, -3.0000],\n",
       "        [ 1.3265,  0.6695, -3.0000],\n",
       "        [ 1.3476,  0.7424, -3.0000],\n",
       "        [ 1.3385,  0.6665, -3.0000],\n",
       "        [ 1.3240,  0.6520, -3.0000],\n",
       "        [ 1.3452,  0.6725, -3.0000],\n",
       "        [ 1.3674,  0.7705, -3.0000],\n",
       "        [ 1.3389,  0.7192, -3.0000],\n",
       "        [ 1.3311,  0.6938, -3.0000],\n",
       "        [ 1.3514,  0.6847, -3.0000],\n",
       "        [ 1.3728,  0.7330, -3.0000],\n",
       "        [ 1.3597,  0.6921, -3.0000],\n",
       "        [ 1.3201,  0.6533, -3.0000],\n",
       "        [ 1.3319,  0.6699, -3.0000],\n",
       "        [ 1.5786,  1.1451, -3.0000],\n",
       "        [ 1.3418,  0.7209, -3.0000],\n",
       "        [ 1.3669,  0.7521, -3.0000],\n",
       "        [ 1.5983,  1.1873, -3.0000],\n",
       "        [ 1.3006,  0.5887, -3.0000],\n",
       "        [ 1.2819,  0.5899, -3.0000],\n",
       "        [ 1.3044,  0.5743, -3.0000],\n",
       "        [ 1.2858,  0.5814, -3.0000],\n",
       "        [ 1.2790,  0.5756, -3.0000],\n",
       "        [ 1.3105,  0.6015, -3.0000],\n",
       "        [ 1.2942,  0.5707, -3.0000],\n",
       "        [ 1.2911,  0.5633, -3.0000],\n",
       "        [ 1.2957,  0.5748, -3.0000],\n",
       "        [ 1.2701,  0.5642, -3.0000],\n",
       "        [ 1.3136,  0.5895, -3.0000],\n",
       "        [ 1.2992,  0.6145, -3.0000],\n",
       "        [ 1.2869,  0.5754, -3.0000],\n",
       "        [ 1.3079,  0.5778, -3.0000],\n",
       "        [ 1.3060,  0.5747, -3.0000],\n",
       "        [ 1.2993,  0.5876, -3.0000],\n",
       "        [ 1.2773,  0.5727, -3.0000],\n",
       "        [ 1.3121,  0.5869, -3.0000],\n",
       "        [ 1.2838,  0.5594, -3.0000],\n",
       "        [ 1.2637,  0.5640, -3.0000],\n",
       "        [ 1.2678,  0.5770, -3.0000],\n",
       "        [ 1.2938,  0.5851, -3.0000],\n",
       "        [ 1.2884,  0.5854, -3.0000],\n",
       "        [ 1.2743,  0.5738, -3.0000],\n",
       "        [ 1.2985,  0.5947, -3.0000],\n",
       "        [ 1.2788,  0.5926, -3.0000],\n",
       "        [ 1.1232,  0.2573, -3.0000],\n",
       "        [ 1.2756,  0.5725, -3.0000],\n",
       "        [ 1.2816,  0.5681, -3.0000],\n",
       "        [ 1.2812,  0.5787, -3.0000],\n",
       "        [ 1.2880,  0.5645, -3.0000],\n",
       "        [ 1.2746,  0.5641, -3.0000],\n",
       "        [ 1.3115,  0.5870, -3.0000],\n",
       "        [ 1.2775,  0.5744, -3.0000],\n",
       "        [ 1.2851,  0.5613, -3.0000],\n",
       "        [ 1.3085,  0.5816, -3.0000],\n",
       "        [ 1.2715,  0.5746, -3.0000],\n",
       "        [ 1.2960,  0.5938, -3.0000],\n",
       "        [ 1.2656,  0.5561, -3.0000],\n",
       "        [ 1.2661,  0.5647, -3.0000],\n",
       "        [ 1.1308,  0.2596, -3.0000],\n",
       "        [ 1.2698,  0.5748, -3.0000],\n",
       "        [ 1.2751,  0.5620, -3.0000],\n",
       "        [ 1.2949,  0.5684, -3.0000],\n",
       "        [ 1.2789,  0.5563, -3.0000],\n",
       "        [ 1.2921,  0.5604, -3.0000],\n",
       "        [ 1.3115,  0.5991, -3.0000],\n",
       "        [ 1.2793,  0.5721, -3.0000],\n",
       "        [ 1.2746,  0.5577, -3.0000],\n",
       "        [ 1.2759,  0.5667, -3.0000],\n",
       "        [ 1.2980,  0.5598, -3.0000],\n",
       "        [ 1.2894,  0.5624, -3.0000],\n",
       "        [ 1.2937,  0.5612, -3.0000],\n",
       "        [ 1.2779,  0.5803, -3.0000],\n",
       "        [ 1.3020,  0.5762, -3.0000],\n",
       "        [ 1.2992,  0.5625, -3.0000],\n",
       "        [ 1.2989,  0.5724, -3.0000],\n",
       "        [ 1.2749,  0.5716, -3.0000],\n",
       "        [ 1.2880,  0.5833, -3.0000],\n",
       "        [ 1.2740,  0.5751, -3.0000],\n",
       "        [ 1.0404,  0.0868, -3.0000],\n",
       "        [ 1.0387,  0.0734, -3.0000],\n",
       "        [ 1.0336,  0.0957, -3.0000],\n",
       "        [ 1.3224,  0.6193, -3.0000],\n",
       "        [ 1.2975,  0.6218, -3.0000],\n",
       "        [ 1.3245,  0.6139, -3.0000],\n",
       "        [ 1.3335,  0.6437, -3.0000],\n",
       "        [ 1.2766,  0.5914, -3.0000],\n",
       "        [ 1.4022,  0.8520, -3.0000],\n",
       "        [ 1.3050,  0.6323, -3.0000],\n",
       "        [ 1.4276,  0.8191, -3.0000],\n",
       "        [ 1.4335,  0.8476, -3.0000],\n",
       "        [ 1.3337,  0.6732, -3.0000],\n",
       "        [ 1.3438,  0.6466, -3.0000]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In_lse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreeEnergy = lse_net(In_lse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04],\n",
       "         [ 9.9905e-01,  1.2243e-03, -7.4551e-04]], grad_fn=<MmBackward0>),)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient1 = torch.autograd.grad(outputs=FreeEnergy, inputs=In_lse,\n",
    "                               grad_outputs=torch.ones_like(FreeEnergy),\n",
    "                               create_graph=True)\n",
    "gradient1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Chain rule: $\\frac{\\partial F}{\\partial F_{base}} = \\frac{\\partial F}{\\partial d_{min}} \\cdot \\frac{\\partial d_{min}}{\\partial F_{base}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5781,  0.6041],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [-0.9128, -1.1751]],\n",
       "\n",
       "        [[ 0.5930,  0.1474],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [-0.9128, -1.1751]],\n",
       "\n",
       "        [[ 0.5370,  0.5697],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [-0.9128, -1.1751]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.0012]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient1[0][:,1].view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0012]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient1[0][:,1].view(-1,1).view(num_drones,1,1) #* gradient0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gradient = gradient0[0] * gradient1[0][:,1].view(-1,1).view(num_drones,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0060, -0.0015],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [-0.0983, -0.1266]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = torch.sum(total_gradient, axis=0)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  2.4013,  -0.6816],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000],\n",
       "          [-40.1663, -51.7077]]], grad_fn=<SumBackward1>),)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1 = torch.autograd.grad(outputs=FreeEnergy, inputs=F_base,\n",
    "                               grad_outputs=torch.ones_like(FreeEnergy),\n",
    "                               create_graph=True)\n",
    "G1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a gradient descent step: $F_{base}^+ = F_{base} - \\eta \\frac{\\partial F}{\\partial F_{base}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "F_base_new = F_base - eta * G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5436, 0.4125],\n",
       "         [0.5437, 0.4126]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_base_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
