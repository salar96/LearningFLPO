{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ab63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3eeb279",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = \"benchmark_data/N10_M4_ends2_seed3\"\n",
    "\n",
    "with open(scene_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "START_locs = data[\"START_locs\"].cpu().detach().numpy()\n",
    "F_base = data[\"F_base\"].cpu().detach().numpy()\n",
    "END_locs = data[\"END_locs\"].cpu().detach().numpy()\n",
    "num_agents = START_locs.shape[0]\n",
    "num_nodes = F_base.shape[-2]\n",
    "dim_ = F_base.shape[-1]\n",
    "T = num_nodes + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df85509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-07-28\n",
      "Read LP format model from file C:\\Users\\salar\\AppData\\Local\\Temp\\tmp4l_ent2q.pyomo.lp\n",
      "Reading time = 0.00 seconds\n",
      "x1: 136 rows, 408 columns, 548 nonzeros\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter MIPGap to value 0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11+.0 (26100.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13620H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 10 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 136 rows, 408 columns and 548 nonzeros\n",
      "Model fingerprint: 0xda968c46\n",
      "Model has 150 quadratic constraints\n",
      "Variable types: 158 continuous, 250 integer (250 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  QMatrix range    [1e+00, 1e+00]\n",
      "  QLMatrix range   [2e-01, 1e+00]\n",
      "  Objective range  [1e-01, 1e-01]\n",
      "  Bounds range     [5e-02, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "  QRHS range       [8e-02, 1e+00]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1486 rows, 908 columns, 5258 nonzeros\n",
      "Presolved model has 100 quadratic constraint(s)\n",
      "Variable types: 658 continuous, 250 integer (250 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 50 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.1341339    0.00000   100%     -    0s\n",
      "*    0     0               0       0.1341339    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   26    0.13413    0.00000   100%     -    0s\n",
      "     0     0    0.00007    0   46    0.13413    0.00007   100%     -    0s\n",
      "H    0     0                       0.1276815    0.00007   100%     -    0s\n",
      "     0     0    0.00007    0   50    0.12768    0.00007   100%     -    0s\n",
      "H    0     0                       0.1241199    0.00007   100%     -    0s\n",
      "     0     0    0.00007    0   91    0.12412    0.00007   100%     -    0s\n",
      "     0     0    0.00007    0   82    0.12412    0.00007   100%     -    0s\n",
      "     0     0    0.00106    0  118    0.12412    0.00106  99.1%     -    0s\n",
      "     0     0    0.00158    0  116    0.12412    0.00158  98.7%     -    0s\n",
      "     0     0    0.00582    0  143    0.12412    0.00582  95.3%     -    0s\n",
      "     0     0    0.00582    0  143    0.12412    0.00582  95.3%     -    0s\n",
      "     0     0    0.00719    0  128    0.12412    0.00719  94.2%     -    0s\n",
      "     0     0    0.00932    0  150    0.12412    0.00932  92.5%     -    0s\n",
      "     0     0    0.00940    0  149    0.12412    0.00940  92.4%     -    0s\n",
      "     0     0    0.01005    0  143    0.12412    0.01005  91.9%     -    0s\n",
      "     0     0    0.01183    0  147    0.12412    0.01183  90.5%     -    0s\n",
      "     0     0    0.01209    0  148    0.12412    0.01209  90.3%     -    0s\n",
      "     0     0    0.01281    0  154    0.12412    0.01281  89.7%     -    0s\n",
      "     0     0    0.01317    0  159    0.12412    0.01317  89.4%     -    0s\n",
      "     0     0    0.01354    0  153    0.12412    0.01354  89.1%     -    0s\n",
      "     0     0    0.01370    0  148    0.12412    0.01370  89.0%     -    0s\n",
      "     0     0    0.01372    0  153    0.12412    0.01372  88.9%     -    0s\n",
      "     0     0    0.01377    0  153    0.12412    0.01377  88.9%     -    0s\n",
      "     0     0    0.01386    0  160    0.12412    0.01386  88.8%     -    0s\n",
      "     0     0    0.01389    0  160    0.12412    0.01389  88.8%     -    0s\n",
      "     0     0    0.01395    0  160    0.12412    0.01395  88.8%     -    0s\n",
      "     0     0    0.01407    0  146    0.12412    0.01407  88.7%     -    0s\n",
      "     0     2    0.01407    0  141    0.12412    0.01407  88.7%     -    0s\n",
      "H  138   144                       0.1216011    0.02672  78.0%   286    1s\n",
      "H  174   203                       0.1175853    0.02672  77.3%   254    1s\n",
      "H  178   203                       0.1147561    0.02672  76.7%   249    1s\n",
      "H  253   268                       0.1121408    0.02672  76.2%   209    1s\n",
      "H  331   367                       0.1080931    0.02672  75.3%   181    1s\n",
      "H  433   484                       0.1080931    0.02672  75.3%   156    1s\n",
      "H  461   484                       0.1051999    0.02672  74.6%   150    1s\n",
      "H  465   484                       0.1050061    0.02672  74.6%   149    1s\n",
      "H  544   607                       0.1050061    0.02672  74.6%   138    1s\n",
      "H  560   607                       0.1021129    0.02672  73.8%   135    1s\n",
      "H  696   757                       0.1021129    0.02672  73.8%   119    1s\n",
      "H  711   757                       0.1019191    0.02672  73.8%   117    1s\n",
      "H  867   892                       0.1019190    0.02674  73.8%   105    1s\n",
      "H  894   892                       0.1019190    0.02674  73.8%   103    1s\n",
      "H  986   981                       0.1019190    0.02674  73.8%  98.2    1s\n",
      "H  995   981                       0.1019190    0.02674  73.8%  98.2    1s\n",
      "H 1100  1061                       0.1019190    0.02674  73.8%  94.4    1s\n",
      "H 1101  1061                       0.1019190    0.02674  73.8%  94.8    1s\n",
      "H 1256  1191                       0.1019190    0.02674  73.8%  92.6    1s\n",
      "H 1357  1303                       0.0990060    0.02674  73.0%  90.3    1s\n",
      "H 1385  1301                       0.0979306    0.02674  72.7%  90.0    1s\n",
      "* 1385  1301              73       0.0979306    0.02674  72.7%  90.0    1s\n",
      "H 1512  1295                       0.0979305    0.04569  53.3%  87.6    3s\n",
      "H 1513  1231                       0.0978438    0.04571  53.3%  87.5    3s\n",
      "H 1520  1174                       0.0976505    0.04571  53.2%  96.3    4s\n",
      "H 1523  1117                       0.0976505    0.04572  53.2%  96.2    4s\n",
      "H 1526  1063                       0.0976505    0.04586  53.0%  96.0    4s\n",
      "  1532  1067    0.04588   22  104    0.09765    0.04588  53.0%  95.6    5s\n",
      "H 1564  1052                       0.0976505    0.04614  52.7%   104    5s\n",
      "H 1569   999                       0.0976505    0.04614  52.7%   104    5s\n",
      "H 1578   948                       0.0967245    0.04614  52.3%   104    5s\n",
      "H 1620   936                       0.0967245    0.04616  52.3%   105    5s\n",
      "H 1656   927                       0.0964446    0.04616  52.1%   104    5s\n",
      "H 1761   946                       0.0964446    0.04616  52.1%   104    6s\n",
      "H 1820   976                       0.0957779    0.04616  51.8%   103    6s\n",
      "H 1940  1036                       0.0957779    0.04616  51.8%   103    6s\n",
      "H 1953   997                       0.0954979    0.04616  51.7%   103    6s\n",
      "H 1961   960                       0.0942767    0.04616  51.0%   103    6s\n",
      "H 2121  1005                       0.0942767    0.04616  51.0%   100    6s\n",
      "H 2241  1064                       0.0939968    0.04616  50.9%  98.5    6s\n",
      "H 2367  1167                       0.0939263    0.04616  50.9%  97.2    6s\n",
      "H 2379  1136                       0.0937511    0.04616  50.8%  97.1    6s\n",
      "H 2537  1229                       0.0935188    0.04616  50.6%  95.6    6s\n",
      "H 2576  1191                       0.0935188    0.04616  50.6%  95.1    6s\n",
      "H 2736  1294                       0.0935188    0.04616  50.6%  93.2    6s\n",
      "H 2739  1271                       0.0931817    0.04616  50.5%  93.2    6s\n",
      "H 2933  1426                       0.0931817    0.04616  50.5%  91.1    6s\n",
      "H 2941  1426                       0.0931817    0.04616  50.5%  91.1    6s\n",
      "H 2984  1424                       0.0910901    0.04616  49.3%  90.7    6s\n",
      "H 3127  1572                       0.0899245    0.04616  48.7%  89.0    6s\n",
      "H 3190  1565                       0.0890213    0.04616  48.1%  88.6    6s\n",
      "H 3293  1546                       0.0847247    0.04616  45.5%  88.2    6s\n",
      "* 3293  1546             100       0.0847247    0.04616  45.5%  88.2    6s\n",
      "H 3336  1569                       0.0842990    0.04616  45.2%  87.9    6s\n",
      "H 4260  2319                       0.0842989    0.04678  44.5%  81.7    6s\n",
      "H 4281  2297                       0.0840323    0.04678  44.3%  81.5    6s\n",
      "H 4581  2530                       0.0840322    0.04678  44.3%  80.2    7s\n",
      "H 4602  2530                       0.0840322    0.04678  44.3%  80.2    7s\n",
      "H 4635  2530                       0.0839927    0.04678  44.3%  80.3    7s\n",
      "H 4644  2501                       0.0833742    0.04678  43.9%  80.4    7s\n",
      "H 5086  2918                       0.0828055    0.04679  43.5%  79.0    7s\n",
      "H 5443  3179                       0.0828055    0.04693  43.3%  78.1    7s\n",
      "H 5463  3106                       0.0815101    0.04693  42.4%  78.2    7s\n",
      "H 5713  3108                       0.0799696    0.04693  41.3%  77.6    7s\n",
      "H 5834  3262                       0.0799693    0.04693  41.3%  77.7    7s\n",
      "H 6095  3508                       0.0799692    0.04693  41.3%  76.9    7s\n",
      "H 6167  3508                       0.0799692    0.04693  41.3%  76.9    7s\n",
      "H 6212  3014                       0.0738215    0.04693  36.4%  76.7    7s\n",
      "* 6212  3014              93       0.0738215    0.04693  36.4%  76.7    7s\n",
      "H 6496  3091                       0.0731225    0.04693  35.8%  76.1    7s\n",
      "H 6743  3385                       0.0731224    0.04694  35.8%  75.9    7s\n",
      "H 6895  3385                       0.0731224    0.04694  35.8%  75.7    7s\n",
      "H 6907  3341                       0.0725727    0.04694  35.3%  75.8    7s\n",
      "H 7078  3473                       0.0725727    0.04694  35.3%  75.5    7s\n",
      "H 7152  3580                       0.0720229    0.04694  34.8%  76.0    7s\n",
      "H 7489  3725                       0.0720228    0.04694  34.8%  76.1    8s\n",
      "H 7914  3931                       0.0707754    0.04694  33.7%  75.3    8s\n",
      "H 8135  3438                       0.0669487    0.04694  29.9%  74.8    8s\n",
      " 15107  7303    0.06514   54   69    0.06695    0.04800  28.3%  67.3   11s\n",
      "H15112  6402                       0.0646465    0.04800  25.8%  67.3   11s\n",
      "H15335  6676                       0.0646465    0.04802  25.7%  67.4   12s\n",
      "H15576  6338                       0.0638539    0.04807  24.7%  67.6   12s\n",
      "H15636  6641                       0.0638537    0.04807  24.7%  67.6   12s\n",
      "H15843  6641                       0.0638536    0.04807  24.7%  67.6   12s\n",
      "H16363  6943                       0.0638536    0.04812  24.6%  67.6   12s\n",
      "H16401  6943                       0.0638536    0.04813  24.6%  67.6   12s\n",
      "H16521  6943                       0.0638535    0.04813  24.6%  67.6   12s\n",
      "H16796  7228                       0.0638535    0.04817  24.6%  67.5   12s\n",
      "H16864  7228                       0.0638535    0.04817  24.6%  67.5   12s\n",
      "H16912  7228                       0.0638535    0.04818  24.6%  67.5   12s\n",
      "H17614  7612                       0.0638535    0.04819  24.5%  67.6   13s\n",
      "H17745  7612                       0.0638535    0.04819  24.5%  67.5   13s\n",
      "H17931  7612                       0.0638535    0.04819  24.5%  67.3   13s\n",
      "H22810 10300                       0.0637847    0.04842  24.1%  65.6   14s\n",
      " 23190 10831    0.06233   69   54    0.06378    0.04842  24.1%  65.6   15s\n",
      "H23309 10831                       0.0637847    0.04843  24.1%  65.6   15s\n",
      "H24598 11371                       0.0637847    0.04848  24.0%  65.5   15s\n",
      "H24732 11371                       0.0637847    0.04848  24.0%  65.6   15s\n",
      "H25311 11835                       0.0637847    0.04851  23.9%  65.5   16s\n",
      "H26328 12290                       0.0637847    0.04852  23.9%  65.4   16s\n",
      " 37373 18107    0.05446   45   81    0.06378    0.04893  23.3%  64.9   20s\n",
      " 49428 23624    0.05765   57   54    0.06378    0.04923  22.8%  63.4   25s\n",
      " 64261 30406    0.06014   52   59    0.06378    0.04957  22.3%  62.6   30s\n",
      " 77396 36655     cutoff   56         0.06378    0.04984  21.9%  62.1   35s\n",
      "H79669 37400                       0.0637716    0.04987  21.8%  62.0   35s\n",
      "H81232 37972                       0.0637716    0.04991  21.7%  61.8   36s\n",
      "H81521 37972                       0.0637716    0.04991  21.7%  61.8   36s\n",
      "H83065 38681                       0.0637716    0.04994  21.7%  61.8   36s\n",
      "H84703 39285                       0.0637715    0.04998  21.6%  61.8   37s\n",
      "H84874 39285                       0.0637715    0.04998  21.6%  61.8   37s\n",
      " 92384 43353    0.05168   40   69    0.06377    0.05009  21.5%  61.3   40s\n",
      "H93418 42150                       0.0633886    0.05010  21.0%  61.3   40s\n",
      "H97198 43123                       0.0631962    0.05016  20.6%  61.0   41s\n",
      "H99239 44333                       0.0631132    0.05019  20.5%  60.9   42s\n",
      "H100557 44251                       0.0630852    0.05020  20.4%  60.8   42s\n",
      "H102930 45814                       0.0630851    0.05026  20.3%  60.6   44s\n",
      "H103505 45814                       0.0630851    0.05026  20.3%  60.6   44s\n",
      "H103618 45814                       0.0630851    0.05026  20.3%  60.6   44s\n",
      "H104448 46485                       0.0630851    0.05029  20.3%  60.5   44s\n",
      "H104969 46485                       0.0630851    0.05030  20.3%  60.5   44s\n",
      " 105965 47212    0.05579   58   82    0.06309    0.05032  20.2%  60.4   45s\n",
      "H106169 47212                       0.0630851    0.05033  20.2%  60.4   45s\n",
      " 120624 52986     cutoff   38         0.06309    0.05055  19.9%  60.1   50s\n",
      " 133682 58349     cutoff   49         0.06309    0.05075  19.5%  59.9   55s\n",
      "H146322 62454                       0.0630661    0.05093  19.2%  59.7   59s\n",
      " 146714 63125    0.06167   58   55    0.06307    0.05094  19.2%  59.6   60s\n",
      "H147057 63125                       0.0630659    0.05094  19.2%  59.6   60s\n",
      "H148184 63123                       0.0630659    0.05095  19.2%  59.6   60s\n",
      "H148570 63706                       0.0630656    0.05096  19.2%  59.6   60s\n",
      "H150088 64295                       0.0630656    0.05098  19.2%  59.6   61s\n",
      "H150936 64294                       0.0630655    0.05099  19.2%  59.5   61s\n",
      "H151714 65007                       0.0630655    0.05100  19.1%  59.6   61s\n",
      "H154547 65592                       0.0630589    0.05102  19.1%  59.5   62s\n",
      "H155028 66221                       0.0630589    0.05102  19.1%  59.5   63s\n",
      "H155887 66221                       0.0630587    0.05102  19.1%  59.5   63s\n",
      "H157270 66785                       0.0630587    0.05107  19.0%  59.5   63s\n",
      "H157369 66785                       0.0630587    0.05107  19.0%  59.5   63s\n",
      "H158278 67493                       0.0630587    0.05109  19.0%  59.5   64s\n",
      "H159911 68117                       0.0630587    0.05110  19.0%  59.5   64s\n",
      " 161682 68742    0.06301   59   58    0.06306    0.05113  18.9%  59.5   65s\n",
      " 174938 73482    0.06216   48   73    0.06306    0.05129  18.7%  59.2   70s\n"
     ]
    }
   ],
   "source": [
    "from GurobiSolver import SolveMIP\n",
    "\n",
    "gap = 0.0\n",
    "best_y, best_eta, cost, elapsed_time = SolveMIP(\n",
    "    START_locs, END_locs, num_agents, num_nodes, T, dim_, F_base, gap=gap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a810859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best y: [[0.5027801  0.33358121]\n",
      " [0.59879445 0.30835901]\n",
      " [0.71553494 0.24699215]\n",
      " [0.83227579 0.18562672]]\n",
      "Best eta: [[[0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]]]\n",
      "Cost: 0.06272790873741246\n",
      "Elapsed time: 537.8825466632843\n"
     ]
    }
   ],
   "source": [
    "print(\"Best y:\", best_y)\n",
    "print(\"Best eta:\", best_eta)\n",
    "print(\"Cost:\", cost)\n",
    "print(\"Elapsed time:\", elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
